\chapter{Future Work}\label{future work}
In this chapter we discuss the investigations, postponed for future work. We organized them into several groups and sort each of them in the descendant order by means of urgency and importance. \cref{fw: prediction process} is dedicated to the prediction process and learning models used in HLH of developed approach. In \cref{fw: search space} we discuss a set of enhancements for the search space that should be performed for better usability. Finally, in \cref{fw: evaluation} we discuss benchmark experiments, required to obtain better evidence about the proposed approach applicability and HH-PC in particular.


\section{Prediction Process}\label{fw: prediction process}
\paragraph{Surrogate optimization generalization.} In \cref{impl: prediction logic} we discussed the process of parameter values prediction based on surrogate models. A classical approach of optimization with surrogates implies two steps. Firstly, the models should be constructed and evaluated by means of their accuracy. If the model is not accurate enough, it could result in a wrong prediction and as a consequence in wrong optimization guidance. After getting a proper model, the second step should be performed, namely, surrogate optimization. It is an actual process of prediction making, which is bases on construction of configuration and using surrogate to estimate its quality. In our work we used a random search surrogate optimization technique instead of implementing a more sophisticated algorithm due to the lack of time. However, the evaluation of random search intensity (\cref{eval:2:pict: random search size}) revealed the urgency of this question, since the quality of random search results is not stable. Therefore, one of the first steps in future work should be the implementation of proper algorithm for surrogate model optimization.


\paragraph{Process metrics for reinforcement learning.} The proposed concept of reinforcement learning-guided parameter space traversal is based on the estimation of relative improvement, performed by the selected parameters (\cref{concept:parameter control}). However, the amount of obtained information may not be enough to truly estimate the configuration quality. We would like to emphasize that it is not a problem of the surrogates, but of the reinforcement learning. Thus, the possible improvement of results may be obtained from adding additional RL metrics. For instance, a RL-based parameter control for EAs~\cite{karafotias2014generic} besides algorithm-dependent metrics, such as genotypic and phenotypic diversity, fitness standard deviation (in population) used also algorithm-independent metrics such as fitness improvement and stagnation counter. While improvement estimation is already used in our concept, the later, namely, a stagnation estimation is a possible candidate for additional learning metrics. Please note, using several such metrics, the surrogate optimization process turns to be a multi-objective OP.


\paragraph{Meta-/offline learning phase.} Relying fully on the online learning, in early stages (while surrogate models cannot be constructed properly due to lack of information) our concept behaves like a random search. However, many studies somehow related to proposed technique reported a significant performance boost in early stages, if the offline or in other words meta-learning was performed. More specifically, in~\cite{feurer2015efficient} (also discussed in \cref{bg: section cash}) the authors performed meta-learning to pre-train their surrogate models for guiding the search at the beginning. In~\cite{uludaug2013hybrid} the authors developed selection hyper-heuristic with mixed learning type, therefore, before an actual run, the offline phase was executed to guide the online selection at early stages. In our system we could use the results of previously executed experiments for similar scenario case to guide right from the start not only the LLH selection, but also the parameter control. 

Separately we would like to highlight a recent study~\cite{biedenkapp-ecai20}, in which the authors also suggest to use reinforcement learning approach to solve a similar \emph{dynamic algorithm configuration} problem. In their work the problem was enclosed in Markov decision processes, which include meta-learning step: learning across the problem instances.


\section{Search Space}\label{fw: search space}
\paragraph{Composition on numerical parameters.} In current implementation of the search space we highlight that it is able to form the parent-child relationship only when parent is of the categorical type (~\cref{impl: search space impl}). However, it may happen, when the dependencies among parameters are based on their numeric values. As an example, imagine the algorithm in which for one parameter values range the first child type should be exposed, while for the other range â€” another child. As a possible solution we propose utilizing an approach, similar to the one used in categorical parameters, but instead of a single activation value, use ranges. Thus, during the prediction propagation step the parameter entity will check all ranges and expose the related children (for more details see description of the \cref{impl: P.F.R.1 + P.F.R.3 implementation pseudocode}).

\paragraph{Constraints among parameters.} Sometimes, the prohibitions for specific values may arise with respect to other parameters. For instance, the value of one numeric parameter should be at least as high as the value of the other. In this case, along with activation values the notion of deactivation values may be introduced.

\section{Evaluations and Benchmarks}\label{fw: evaluation}
The presented in \cref{eval} evaluation contains only the coarse-grained set of experiments, however, the proposed in this thesis concept of merging algorithm selection and parameter control comprises several building blocks, each of which should be thoroughly evaluated separately. Therefore, here we propose a set of fine-grained directions for future evaluation.
 
\subsection{Use-Case Evaluation}
\paragraph{Optimization problems.} The advantage of hyper-heuristics lays in their ability to tackle a \emph{family} or \emph{class} of optimization problems, defiled by underlying low-level heuristics. Due to this flexibility of hyper-heuristics in general and the proposed concept in particular, by changing the domain-dependent components of low-level heuristics one will be able to tackle numbers of other optimization problems. Our evaluation in \cref{eval} is performed only on a traveling salesman problem. However, the combinatorial problems also include other types such as \emph{flow-shop scheduling}~\cite{gupta2006flowshop}, \emph{nurse rostering}~\cite{cheang2003nurse}, \emph{knapsack}~\cite{ross1989stochastic}, \emph{n-queens}~\cite{rivin1994n} and many other real-life and synthetic optimization problems. Used in our implementation jMetalPy framework~\cite{benitez2019jmetalpy} out of the box includes domain-dependent components for aforementioned knapsack problem, but thanks to its flexibility it is relatively easy to add other problem types.

\paragraph{Construction hyper-heuristics.} The idea discussed in \cref{bg: hh} of construction hyper-heuristics implies the algorithm creation from the building blocks. In our work we treated the \emph{mutation, crossover, selection types} as the categorical parameters of underlying LLHs. However, in used jMetal and jMetalPy frameworks these parameters are implemented as separate operators that should be specified during the algorithm instantiation. Therefore, the proposed concepts of search space and RL-based parameter assignment may be evaluated also for the construction hyper-heuristic cases.

\paragraph{Automatic machine learning.} Making a step further from construction hyper-heuristic, an orthogonal research direction of an automatic machine learning field is exposed. The framework reviewed in \cref{bg: section cash} deals with the construction of machine learning pipelines that operate on datasets. In our approach, the proposed representation of the search space may be used to define the ML pipeline structure. For instance, the first several levels of our search space may encode the data preprocessing in ML pipeline. The successive level denotes the ML algorithm instances, while the final level is dedicated to validation technique. This system use-case should be evaluated against the already proposed solutions in automatic machine learning field, for instance, AutoSklearn~\cite{feurer2015efficient}, TPOT~\cite{olson2019tpot} and many others.


\subsection{System Configuration Evaluation}
The benchmark set, presented in \cref{eval:2} is dedicated to the implemented concept configuration evaluation. Due to the time constraints, we were able to probe only a few system modes and settings. Nevertheless, a vast bunch of experiments should be conducted urgently.

\paragraph{Modes of operation.} In \cref{eval:2} only to HH-PC mode was benchmarked. However, it includes two other modes, namely MH-PC and HH-SP, which configuration should be evaluated separately by means of (1) underlying surrogate models settings, (2) adding more LLHs. While the influence of the first direction was partially relieved in \cref{eval:2}, the second direction, which is relevant only to HH-SP and HH-PC modes requires more clarification. By extending the search space with more LLHs, the RL will require more information (in terms of external iterations) for tuning available LLHs and differentiating among them by means of their performance. It is clear that with LLH number growth, the final performance gap between the best performing (tuned) LLH and HH-PS (HH-PC) will increase. The goal of these experiments will lay in a dependency estimation between search space complexity and the introducing RL-based search overhead.

\paragraph{Reinforcement learning configuration.} Another worth-to-mention course of investigation is the influence of currently implemented RL-based optimization approach. The experiments with different TSP instances showed inefficiency of strictly defined time-based external iterations. For instance, with kroA100 TSP most of the used LLHs reached the local optimum after a couple of first external iterations and settled there till the end of optimization process. Thus, the \emph{adaptive external iteration time} should be introduced, which analyze the process stagnation and thus, be able to terminate the optimization session earlier. 

On the contrary, instead of time-based mechanism for external iteration termination, one may also limit the number of internal iterations performed by LLH. Using this mechanism the set of use-cases may be extended, with the expensive for evaluation optimization problems.