\chapter{Background and related work analysis}\label{bg}
\paragraph{The structure} is the same the beginning of introduction, but way more detailed.  


\section{Optimization problems and solvers}\label{bg:opt problems and solvers}

\subsection{Definition of optimization problems}
\todoy{Need to find a classification of optimization problems.}

\subsection{Optimization problems solvers}
\todoy{rename to smth like "Types | Classes of solvers"} 
Some (but not only) literature: \cite{bergstra2011algorithms}
\subsubsection{Exact solvers}
\subsubsection{Approximate solvers}
\subsubsection{Comparison:} Pros and cons of both \cite{hromkovivc2013algorithmics}


\section{Approximate solvers of optimization problems}
TSP as the running example. I guess, I will introduce it as an example of perturbation problems in previous section.\ref{sec:opt problms, solvrs}

\subsection{Heuristics}
\subsubsection{Definition}
\subsubsection{Examples}
\subsubsection{Conclusion}
Heuristics are strictly problem dependent and each time require adaptations.

\subsection{Meta-heuristics}
\subsubsection{Definition}
\subsubsection{Classification}
\subsubsection{Examples}
We distinguish following examples among all existing meta~-heuristics, since later we use them as the LLH in developed hyper~-heuristic.
\paragraph{GA}
\paragraph{SA}
\paragraph{ES}
\subsubsection{No-free-lunch theorem}
NFL is the problem of heuristics\cite{wolpert1997no}
\subsubsection{Exploration-explotation balance}
\subsubsection{Conclusion} 
Proper assignment of hyper~-parameters has great impact on exploration-exploitation balance and those on (meta)~-heuristic performance. 

\subsection{Hybrid~-heuristics}
\subsubsection{Definition}
\subsubsection{Examples}
\paragraph{Guided Loca Search (GLS) + Fast Local Search} \cite{tsang1997fast}
\paragraph{Direct Global + Local search} \cite{syrjakow1999efficient}
\paragraph{Simulated Annealing + Local Search} \cite{martin1996combining}
\subsubsection{Conclusion}

\subsection{Hyper~-heuristics}
\subsubsection{Definition}
\subsubsection{Classification}
\paragraph{Search space:} heuristic selection, heuristic generation
\paragraph{Learning time:} on-line learning hyper-heuristics, off-line learning hyper-heuristics, no-learning hyper-heuristics
\paragraph{Other classification characteristics} from \cite{surv:kerschke2019automated}, \cite{burke2019classification}, mb smth else. For instance, hyperparameter tuning
\subsubsection{Examples}% should I present it in following sections?
\cite{surv:drake2019recent} (Online algorithm selection at page 27); \cite{surv:kerschke2019automated}
\subsubsection{Conclusion...?} they usually (need to check it) have lack of parameter control

\subsection{Conclusion on approximate solvers}
\paragraph{Pros and cons of heuristics} - too problem dependent
\paragraph{Pros and cons of meta~-heuristics} - no LLH selection, strict to one problem
\paragraph{Pros and cons of hybrid~-heuristics} - no LLH selection, strict to one problem ? 
\paragraph{Pros and cons of hyper~-heuristics} - no parameter control?


\section{Parameter tuning}\label{bg: parameter tuning}
\todoy{The goal of section: analysis of existing systems for hyper~-parameter optimization (tuning), weaknesses and strength of each of the system}
\todoy{Should I include the analysis from the code-basis point of view? If no, I do not see what should I conclude from this section exect "there are numer of parameter tuning systems each of them has pros and cons..}

\subsection{Parameter tuning problem definition, approaches (grid, random, mh..)}

\subsection{Systems for parameter tuning}

\subsubsection{IRACE}
\paragraph{approach} \cite{irace:lopez2016irace}
\paragraph{pros and cons}

\subsubsection{SMAC}
\paragraph{approach description}

\subsubsection{BOHB}
\paragraph{approach description}

\subsubsection{AUTO-SKLEARN}
\paragraph{CASH (Combined Algorithm Selection and Hyperparameter optimization) problem}
\paragraph{pros and cons (on-line or off-line, problems to solve, extensibility)}\cite{autosklearn:feurer2015efficient}

\subsubsection{BRISEv2}
\paragraph{approach description}

\todoy{Other systems?}

\paragraph{Table for comparison}

\subsubsection{Conclusion}
depends on the resolved question in todo...


\section{Parameter control}\label{bg: parameter control}
\subsection{definition, approaches}
\subsection{system examples}
\subsection{Conclusion} impact of parameter control based on other's evaluation


\section{Conclusion}

The meta-heuristic systems designers reported positive impact of parameter control embedding. 
However, as the outcome of the no-free-lunch theorem, those systems can not tolerate broad range of problems, for instance, problem classes.
In other hand, hyper~-heuristics are designed with an aim to select the low level heuristics and those propose a possible solution of problem, stated in no-free-lunch theorem, but the lack of parameter control could dramatically decrease the performance of LLH (probably, I need to find a prove of this, or rephrase).

\paragraph{Scope of work defined.} In this thesis we try to achieve the best of both worlds applying the best fitting LLH and tuning it's parameters while solving the problem on-line.
