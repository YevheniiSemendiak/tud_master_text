\chapter{Background and Related Work Analysis}\label{bg}
In this chapter we provide reader with the base knowledge in field of Optimization Problems and the process of their solving.
The reader who is an expert in field of Optimization and Search Problems could find this chapter as an obvious discussion of well-known facts. If the notions of \textit{Parameter Tuning} and \textit{Parameter Control} seems like two different names for one thing, we encourage you to read this chapter carefully.
We highly recommend for everyone to refresh the knowledge of sections topics and examine the examples of Hyper-Heuristics in \ref{bg: hh examples} and Systems for parameter tuning in \ref{bg: parameter tuning expamples} since we use them later in concept implementation.

\paragraph{In this chapter we...} 


\section{Optimization Problems and their Solvers}\label{bg:opt problems and solvers}


\subsection{Optimization Problems}\label{BG: subsection OPs}
%https://www.solver.com/problem-types
% need to add some kind of catchy intro, here or in previous parts of this section.
While the Search Problem (SP) defines the process of finding a possible Solution for the Computation Problem, an Optimization Problem (OP) is the special case of the SP, focused on the process of finding the 'best possible' Solution for Computation Problem~\cite{goldreich2010p}. 


In this thesis we focus on the Optimization Problems — a special case of the Search Problems.


A lot of conducted studies in this field have tried to formalize the concept of OP, but the underlying notion such a vast that it is almost impossible to exclude the application domain from the definition. The description of every possible Optimization Problem and all approaches for solving it are out of the scope of this thesis. However, a birds-eye view should be presented in order to make sure that reader is familiar with all notions used through this thesis. 


In \cite{biegler2004retrospective,figueira2014hybrid,amaran2016simulation} authors distinguished OP characteristics that overlap through each of these works and those we would like to start from them.


First, let us define the subject of the Optimization. In general, it could be imagined as the Target System (TS) displayed on picture \ref{bg:pic:Target System}. Analytically it could be represented as the function $Y = f(X)$. Informally it accepts the information with its \textit{inputs} \textbf{X} sometimes also called variables or parameters, performs a \textit{Task} and produces the result on its \textit{outputs} \textbf{Y}.

\svgpath{{graphics/Background/}}
\begin{figure}
	\centering
	\includesvg[width=0.5\textwidth]{TargetSystem}
	\caption{Target System}
	\label{bg:pic:Target System}
\end{figure}

Pair of $X$ and respective $Y$ form a \textit{Solution} for Computation Problem.
All possible inputs $X$ form a \textit{Search Space}, while all outcomes $Y$ form an \textit{Objective Space}.
The Solution could also be characterized by the \textit{objective} value(s) — a quantitative measure of TS performance that we minimize or maximize. 
We could obtain those value(s) directly by reading the $Y$, or indirectly for instance, noting the time TS took to produce the output $Y$ for given $X$. 
The Solution objective value(s) form object(s) of Optimization. 
For the sake of simplicity we here use $Y$, \textit{outputs}, \textit{objectives} and $X$, variables, \textbf{parameters(?)}% will decide later
 interchangeably.


Next, let us highlight the Target System characteristics.
Among mentioned in \cite{biegler2004retrospective,figueira2014hybrid,amaran2016simulation} we found those the most important:
\begin{itemize}[itemsep=8pt]
	\item \textbf{Input data types} of $X$ is a crucial characteristic. The variables could be either \textit{discrete} where representatives are binary strings, integer-ordered or categorical data, % One could apply mixed integer linear (nonlinear) programming here (MILP, MINLP) \cite{biegler2004retrospective}.
	\textit{continuous} where variables are usually a range of real numbers, or \textit{mixed} as the mixture of previous two cases.

	\item \textbf{Constrains} are functional dependencies that describe the relationships among inputs and defile the allowable values for them.

	\item \textbf{Amount of knowledge} TS exposes about the dependencies between $X \rightarrow Y$ or objective values. With respect to this knowledge, the Optimization could be \textit{White Box} — the TS exposes it internals fully, so it is even possible to derive the algebraic model of TS.
	%\textit{Gray Box} - the amount of exposed knowledge is significant, but not enough to build the algebraic model.
	\textit{Black Box} — the exposed knowledge is mostly negligible.
	%In this case the Derivative Free Optimization approaches (such as Surrogate Optimization, different Meta-|Hybrid-|Hyper-Heuristics)  are applicable.

	%\paragraph{Dependency types} could be  The inputs to outputs dependencies the of Target System could also be distinguished form perspective of linearity \cite{biegler2004retrospective,figueira2014hybrid}.
	%\textit{Linear dependencies} reveal the Linear Programming Optimization approaches, while with \textbf{Nonlinear dependencies} one should consider Nonlinear Programming.

	\item \textbf{Dependencies randomness} One of possible challenges, while obtaining the knowledge about TS is uncertainty of output. Ideal case is the \textit{deterministic} dependency between $X$ and $Y$, however in most of real-world challenges engineers tackle with the \textit{stochastic} systems whose output is affected by random processes. 

	\item \textbf{Cost of evaluation} is the amount of resources (computational, time, money, etc.) TS will spend to obtain the result for particular input. It varies from very cheap if the TS is a simple algebraic formula and Task is to evaluate it, to very expensive if the TS is a complex Neuron Network and the Task is to train it on data.

	\item \textbf{Number of objectives} could be either \textit{Single}, or \textit{Multiple}. According to the number of objectives, the result of optimization will be either single Solution, or set of non-dominated (Pareto-optimal) Solutions \cite{deb2014multi}.

\end{itemize}


Combining different characteristic, one could obtain broad range of Optimization Problem types.


In this thesis we tackle such a real life problems as bin packing, job-shop scheduling or vehicle routing.
The mentioned above problems has been shown to impose $NP-complete$ (meaning that they are both $NP$ and $NP-hard$) computational complexity \cite{garey1979computers}.


As an example, let's grasp these characteristics for Traveling Salesman Problem (TSP) \cite{applegate2006traveling} — an instance of vehicle routing problem and one of the most studied combinatorial OP, yet still remaining one of the most challenging (here we consider deterministic, symmetric TSP).
The informal definition of TSP is as follows: 'Given a set of cities and the distances between each of them, what is the shortest path to visit each city once and return to the origin city?'.
The input data (path) is a vector of city indexes, and those the type is a non-negative integers \textit{0, 1, 2...}.
There are two constrains on path: it should contain only unique indexes (those, each city will be visited only once) and it should start and end from the same city. 
The TSP distance (or cost) matrix here plays role of Target System, clearly that this TS exposes all internal knowledge and those it is the white box.
Since the cost matrix is fixed and not changing, the TS is considered to be deterministic, cost for two identical paths are always the same (although there exist Dynamic TSP where the cost matrix changes while computing the path cost to reflect a real-time traffic information updates while traveling \cite{cheong2011dynamic}).
It is extremely cheap to compute a cost for given path using cost matrix, those overall Solution evaluation in this TS is cheap.
Since we are optimizing only the route distance, it is a Single objective OP.


\subsection{Optimization Problem Solvers}\label{BG: subsection OP Solvers}
Any Optimization Problem could be solved by an exhaustive search. 
But when the problem size significantly increase, the amount of time needed for an exhaustive search becomes infeasible and in most cases even relatively small problem instances could not be solved by an enumeration.

Here different techniques come into play, but the provided by Target System characteristics of Optimization Problem could restrict and sometimes strictly define the applicable approach.
For instance, imagine you have white box deterministic TS with discrete constrained input data and cheap evaluation. The OP in this case could be described using Integer Linear Programming \todoy{ref} approaches, or heuristics \todoy{ref}. If this TS turned out to be a black box, the ILP approaches are not applicable and one should consider using heuristics \cite{biegler2004retrospective}.


Again, there exist a lot of different facets for OP Solvers classification, however they are a subject of surveying works. Here as the point of interest we decided to highlight two of them.

From the perspective of solution quality:
\begin{itemize}
	\item \textbf{Exact} Solvers are those algorithms that always provide an optimal Solution for OP.
	\item \textbf{Approximate} Solvers produce a sub-optimal output with guarantee in quality (some order of distance to the optimal solution).
	\item \textbf{Heuristics} Solvers do not give any worst-case guarantee for the final result quality.
\end{itemize}

From the perspective of solution availability:
\begin{itemize}
	\item Algorithms that expose the Solution \textbf{at the end} of their run.
	\item In opposite, \textbf{anytime} algorithms designed to improve the solution quality step-by-step while solving the OP and those, intermediate results are naturally accessible. 
\end{itemize}

Each if this algorithm families has own advantages and disadvantages in comparison to other, and if the property of solution availability is clear, the solution quality faced require more detailed description.

\subsubsection{Solution Quality Classes}
\paragraph{Exact Solvers.}
As we stated previously, the exact algorithms are those which always solve an OP to optimality.

For some OP it is possible to develop an algorithm that is much faster than exhaustive search — it runs in super-polynomial time providing an optimal solution. As it stated in \cite{woeginger2003exact}, if the common belief $P \ne NP$ is true, those super-polynomial time algorithms are the best we can hope to get when dealing with an NP-complete problem.

By the definition in \cite{fomin2013exact}, the objective of an exact algorithm is to perform better (in terms of running time) than exhaustive search.
In both works \cite{woeginger2003exact} author had enumerated the main techniques for exact algorithms designing each of which enhance this 'better' independently.
A brief explanation of them will help to refresh the knowledge.

\begin{itemize}
	\item \textbf{Branching and bounding} techniques when applied to origin problem, split the search space of all possible solutions (e.g. exhaustive search space) to a set of smaller sub-spaces (more formally, branching the search tree into subtrees). This is done with an intent to later prove that some sub-spaces never lead to an optimal solution and those could be ignored in order to speed-up the search.
	
	\item \textbf{Dynamic programming across the Subsets} techniques in some sort could be combined with the mentioned above branching techniques. After forming the Search Space subsets (branches), the dynamic programming attempts to derive solutions for smaller subsets and combine them into solutions for lager subsets unless finally derive a solution for original search space.
	
	\item \textbf{Problem preprocessing} could be applied as an initial phase of the solving process. This technique is dependable upon the underlying OP, but when applied properly, significantly reduce the running time. A toy example from \cite{woeginger2003exact} elegantly illustrate this technique: imagine problem of finding a pair of two integers $x_i$ and $y_i$ that sum up to integer $S$ in $X_k$ and $Y_k$ sets of unique numbers ($k$ here denotes the size of a set). The exhaustive search will enumerate all $x-y$ pairs in $O(k^2)$ time. But one could first preprocess the data by sorting it, after that use bisection search repeatedly in this sorted array and search for $k$ values $S - y_i$, the overall time complexity becomes $O(k\log(k))$.
\end{itemize}


\paragraph{Approximate Solvers.} When the OP cannot be solved to optimal in polynomial time, people start thinking in alternative solutions and mostly relax their requirements. Approximate algorithms are representatives of the theoretical computer science field that have been created in order to tackle the computationally difficult white box OP. %In words of Garey and Johnson it means "I can't find an efficient (polynomial time) algorithm, but neither can all of these famous people."
%If the widely believed conjecture $P \ne NP$ is true, a wide range of OPs (ILP) are $NP-hard$ and cannot be solved with exact solvers in polynomial time, those require relaxation either in efficiency or quality of optimization.


In contradistinction to exact, approximate algorithms relax the quality requirements and solve an OP effectively with the provable assurances on the result distance from an optimal solution \cite{williamson2011design}. The worst case results quality guarantee is crucial in design of approximation algorithms and involves mathematical proofs. 

One may ask a question ``How do these algorithms guarantee on quality, if the optimal solution is unknown ahead?'' Certainly it sounds contradictive since knowing the optimal solution cancels an optimization problem itself. The answer to this question highlights a key technique in the design of approximation algorithms.

In \cite{williamson2011design} authors stated several techniques of an approximate solvers design. The \textbf{Linear Programming} relaxation plays a central role in approximate solvers. It is well known that solving the ILP is $NP-hard$ problem, however it could be relaxed to polynomial-time solvable LP. %Those, one of techniques is relaxation of ILP to LP. An optimal solution for LP will have value $S_LP \le S_IP = OPT$ (for the minimization case). Here we could derive a lower bound for the original minimization or upper bound for maximization problem. 
Later fractional solution for the LP should be rounded to obtain a feasible solution for the ILP. % that is within a cerain factor $f$ the value of the LP $S_LP$. Thus, the ILP solution will cost no more than $f * OPT$.
Different rounding strategies define separate technique for approximate solvers \cite{williamson2011design}: 
\begin{itemize}
	\item \textbf{Deterministic rounding} follows predefined ahead strategy for rounding.
	\item In \textbf{Randomized rounding} the algorithm will do a round-up of each fractional solution value to integer uniformly.
\end{itemize}

Another technique in contrast to rounding requires building a \textit{dual linear program} for LP. This technique utilizes a \textit{weak} and \textit{strong duality} properties of dual linear program to derive the distance of approximate from an optimal solution. Other properties of dual linear program form a basis for \textbf{Primal-dual} algorithms. They start with a dual feasible solution and use dual information to derive a solution (possible infeasible) for primal linear program. If the \textit{primal} solution is infeasible, algorithm modifies dual solution to increase the values of the dual objective function \cite{williamson2011design}. 

\paragraph{Heuristics.} In contradiction to approximate solvers, heuristics do not provide any guarantee on the Solution quality. They are applicable not only to white box TS, but also in black box cases. They are sufficient to quickly reach immediate, short-term goal for those problems, where finding an optimal solution is impossible or impractical because of the huge search space size.

Heuristics could be defied as rules of thumb, or strategies to use available from TS and obtained solution information to control a problem-solving process \cite{pearl1984intelligent}. Scientists draw the inspiration for heuristics creation from all aspects of our being — from observations of how humans tackle problems using intuition to mechanisms discovered in nature.


As well as in previous approaches, there exists a lot of facets for heuristic approaches classification.
However, from the \textit{level of generality} perspective exist:
\begin{itemize}
	\item \textbf{Simple heuristics} are algorithms, specifically designed to tackle concrete problem. They use the domain knowledge from Optimization Problem to gain a performance. Simple heuristics do not provide any mechanisms to escape a local optimum and those could be easily trapped to it \cite{pearl1984intelligent}.
	
	\item \textbf{Meta-heuristics} are high-level heuristics that do not require problem domain knowledge and those could be applied to broad range of OPs. Often they are nature-inspired and comprise mechanisms to escape local optima and also converge slower than simple heuristics \cite{bianchi2009survey}.
	
	\item \textbf{Hybrid-heuristics} arise combinations of two or more meta-heuristics. It could be imagined as a combination of recipes from the cook book to create something new and probably better, merging the best characteristics.
	
	\item \textbf{Hyper-heuristics} is a heuristic that operates not on the Search Space constructed for the OP, but on a set of low-level heuristics, used to solve the Optimization Problem. The research and experiments have shown that some meta-heuristics perform better for some types of problems, but poorly for other. In addition, it could happen so that for different instances of the same problem, various meta-heuristics provide unexpected performance metrics. Even in different stages of the problem solving process the dominance of one heuristic over another could change. Here comes hyper-heuristics to intelligently pick suitable meta-heuristics to solve a problem \cite{burke2003hyper}.
\end{itemize}

Later, in following section~\ref{bg: heuristics section}, dedicated to heuristics, we discuss each of aforementioned approaches in more details including examples.


\subsubsection{Selecting Best Suited Solver}
An old engineering slogan says, ``Fast, Cheap or Good? Choose two.''

And here we should make a decision, which way to follow.
In one hand, we have an exact solver for the Optimization Problems. As we mentioned above, it guarantees to derive an optimal solution, always. Today, tomorrow or in next century, but an exact solver will find it. The only thing we need is simply (or not) construct an exact algorithm for our specific problem. This approach definitely provides us \textit{good}, say the best, quality of final solution, however it sacrifices simplicity and speed in building a solver and solving the problem.


On the other hand we have an approximate solver. It does not guarantee to find an optimal solution, but instead reasonably good one. The required effort for constructing an algorithm and proving its preciseness remains the same as for exact solvers, from our perspective. Nevertheless, this approach beats the previous one in terms of speed in problem solving, sacrificing a reasonably small amount of the result quality. Sounds like a good deal.


Last but not least, remains bright and shining heuristic. It is super-fast in comparison to previous two approaches in problem solving. It is much easier to apply for your specific problem — no need to build complex mathematical models or prove theorems. However, the biggest flaw in this approach is that it does not guarantee to provide an optimal solution at all and those, one should consider use it up to own risk.


Modern world is highly dynamic, in business survive those who faster and stronger. In most cases former plays settle role for success and great products build iteratively, enhancing existing solution step-by-step and throwing away unlucky decisions quickly. As we mentioned in \ref{BG: subsection OPs} this thesis is dedicated to facing a real-life problems such as TSP. The problems showed to be $NP-complete$ that is why we are not allowed to apply exact solvers, only approximate and heuristics left. In both cases we are sacrificing a solution optimallity, although in different quantities, but the heuristic algorithms repay in time-to develop and getting first results. It motivates us to follow the heuristic approach through the thesis.

In following section \ref{bg: heuristics section} we shortly survey different types and examples of heuristics with their properties, weaknesses and ways to deal with them in order to select the best suited heuristics class.


\section{Heuristic Solvers for Optimization Problems}\label{bg: heuristics section}
Before diving into description of heuristics and their concrete examples, it is worth to scratch a use-case. We base our descriptions on mentioned in section \ref{BG: subsection OPs} Traveling Salesman Problem (TSP) \cite{applegate2006traveling}, which informal definition sounds as: 'Given a set of cities and the distances between each of them, what is the shortest path to visit each city once and return to the origin city?'. 
The input data $X$ to our heuristics will be the distance matrix (or coordinates to build this matrix) between cities, as an output from heuristics we expect to get the sequence of cities, describing the route plan.

In general, heuristics when applied to particular problem do not use the gradient or Hessian matrix of the objective function for optimizations \cite{boussaid2013survey}.

Most heuristic approaches imply and use following concepts:
\begin{itemize}
	\item \textbf{Neighborhood} defines the set of Solutions, which could be derived performing one step of heuristic search.
	\item \textbf{Iteration} could be defined as the action (or set of actions) done over Solution in order to derive a new, hopefully better Solution.
	\item \textbf{Exploration} (diversification) is the process of discovering unvisited and high quality parts of the Search Space.
	\item \textbf{Exploitation} (intensification) is the usage of already accumulated information about the Search Space to derive a new one, but similar to existing Solutions.
\end{itemize}


%Naturally, there are lots of characteristics that could be used to classify heuristics starting from the use of memory, kind of neighborhood, way to derive a solution (construction or perturbation) or number of solutions carried from one iteration to following. 

\subsection{Simple Heuristics}
As we mentioned above, the simple heuristics are domain dependent algorithms, designed to solve a particular problem.
Since each application is highly defined by the concrete OP instance, it is hard to distinguish commonalities among simple heuristics except of only domain knowledge utilization.


Two main types of simple heuristics were distinguished in~\cite{burke2019classification}. The first is a \textit{perturbative}, or \textit{Local Search} heuristics which operates on completely created Solutions. The prominent example of Local Search is a \textit{Hill Climbing}. This approach plays a central role in many high-order heuristics. The second is a \textit{constructive} heuristic which step-by-step mature partial candidate Solution.

A concrete example of Local Search is \textit{Greedy Algorithm}, also known as \textit{Best Improvement Local Search}. When applied to Traveling Salesman Problem, it tackles the path construction by simply accepts the next closest city from currently discovered. In general, the Greedy Algorithm follows the logic of making a sequence of locally optimal decisions. 


Other instance of Local Search is \textit{First Improvement} Local Search \cite{voudouris1999guided}. This algorithm accepts a better Solution as soon as it finds it. The advantage of this methodology over the Greedy Algorithm is the velocity of Search Space traversing, since to perform a move, Best Improvement first should evaluate entire Neighborhood, which in some cases could be enormously huge.

Indeed, the use of simple local search heuristics might not lead to a globally optimal solution, since the optimization result is fully defined be the starting point, but the advantage is a simplicity in implementation \cite{williamson2011design}.

 
\todoy{need to add more info, probably structurize somehow}


\subsection{Meta-Heuristics}
A meta-heuristic is an algorithm created to solve wide range of hard optimization problems without need to deeply adapt to each problem. 


The prefix \textit{meta} indicates that these algorithms are heuristics of a \textit{higher level} when compared to a simple problem specific heuristics. A typical meta-heuristic structure could be imagined as $n-T--H$ (template-hook) framework variation pattern. The template part is problem independent and fixed from changes, it forms a core of an algorithm and usually exposes \textit{hyper-parameters} for tuning. The hook parts are domain dependent and those should be adapted for problem in hand.
Also, the optimizer could contain stochastic components, what gives it an ability to escape from local optimum. However,it also means that the output is stochastic and could not guarantee the result preciseness \cite{boussaid2013survey}.


The success of meta-heuristic on a given OP depends on the balance between exploration and exploitation. If there is a strong bias towards diversification, the solving process could naturally skip a good solution while performing a huge steps over the search space, but when the intensification dominating, the process will quickly converge to local optima. A simple heuristic approaches suffer from high exploitation dominance. 
In general, the difference among existing meta-heuristics laid in a particular way how they try to achieve this balance, but the common property is that most of them are inspired by processes in nature — physics, biology, ethology or evolution.


\subsubsection{Classification}
The research of meta-heuristics field arise even before 1940s, when they had being used but not formally studied. In the period of between 1940 and 1980s appear first formal studies and later till 2000 the field of meta-heuristics appears in wide and numbers of methods were proposed. The period from 2000 and until now in \cite{sorensen2017history} authors refer as the time of framework growth. It is now a time, where meta-heuristics widely appear as frameworks, requiring a domain specific adaptation and providing a reusable core. 

The development of novel methods has slowed down, the research community began to organize these algorithms and many classification facets were distinguished. As an example, the research conducted by \cite{birattari2001classification} highlights following characteristics:
\begin{itemize}
	\item The \textbf{method of walk-through} could be either trajectory based or discontinuous. The former one corresponds a closed walk on the neighborhood where Simulated Annealing, Tabu Search or Local Search are typical examples. The later one allows large jumps in the search space where examples are Variable Neighborhood Search, Lin-Kernighan Heuristic for the TSP \cite{lin1973effective}.
	
	\item By the \textbf{number of concurrent solutions} we distinguish \textit{single-point} and \textit{population-based} approaches with Tabu Search, Simulated Annealing, Iterated Local Search examples of former and Evolutionary Algorithms, Ant Colony Optimization, Particle Swarm Optimization are instances of later.
	
	\item From the \textbf{memory usage} perspective highlighted those which \textit{does utilize memory} and \textit{memory-less} approaches. The Tabu Search explicitly use memory in forms of tabu lists, but Simulated Annealing is memory-less.
	
	\item \textbf{Neighborhood structure} could be either \textit{static} or \textit{dynamic}. Most local search algorithms such as Simulated Annealing and Tabu Search are based on static neighborhood. The Variable Neighborhood Search is an opposite case, where various structures of neighborhood are defined and interchanged while solving an OP. 
\end{itemize}

Picture \ref{BG: MH classification} illustrates the summarized classification including some other characteristics and well-known meta-heuristic samples \cite{wiki_MH_classification}.
\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{graphics/Background/Metaheuristics_classification}
	\caption{Meta-heuristics Classification}
	\label{BG: MH classification}
\end{figure}


\subsubsection{Examples}\label{BG: MH Examples}
We shortly describe some prominent and widely used meta-heuristics, since later we use them as the LLH in developed Hyper-Heuristic, described in section~\ref{Impl: LLH}.


\paragraph{Evolutionary Algorithms (EAs).} Evolutionary Algorithms are directly inspired by the processes in nature, described in evolution theory. The common underlying idea in all these methods is as following. If we put a population of individuals (Solutions) into an environment with limited resources (population size limit), a competition processes cause natural selection, where only the best individuals survive (compared by the object of optimization for given subject TS )~\cite{eiben2015evolutionary}.
Tree basic actions are defined as operators of EAs: the \textit{recombination} that is applied to selected candidates Solutions (parents) among available in population to produce new ones (children); \textit{mutation} occurs in one candidate to turn it into a new Solution. Applying both operators on the parents create a set of new Solutions — the offspring, whose results evaluated using TS. After that, the \textit{selection} operator applied among available Solutions (parents and offspring) to keep the population size within defined boundaries. This process is repeatedly iterated until some termination criteria fulfilled, for instance maximal number of iteration reached, amount of TS evaluations exceed, or Solution with required quality found. The work-flow of EA depicted on picture \ref{bg:pic:EAs}.

\begin{figure}
	\centering
	\includesvg{EA}
	\caption{Evolutionary Algorithm Control Flow}
	\label{bg:pic:EAs}
\end{figure}

\paragraph{Genetic Algorithm (GA).} It is the first association coming into mind when you hear words 'Evolutionary Algorithms'. GA traditionally has a fixed work-flow: with given initial population of $\mu$ usually randomly sampled individuals, the parent selection operator shuffles initial set to create a random pairs of parents, after that the crossover operator is applied to each pair with probability $p_c$ to produce children. Then newly created Solutions individually undergoes mutation operator with independent probability $p_m$. Resulting offspring perform tournament within selection operator and $\mu$ survivals replace current population~\cite{eiben2015popular}. Distinguishable characteristics of simple GA are following: Solution representation in form of bit-strings, one-point crossover and bit-flip usage as the recombination and mutation operators respectively and a generational selection operator (survive only children).

\paragraph{Evolution Strategy (ES).} In contradiction to GA, Evolution Strategy algorithms are working in a vector space of Solution representation and distinguish $\mu$ individuals population size and $\lambda$ offspring generated in one iteration. They induce a very useful feature of \textit{self-adaptation}: changing the mutation step sizes depending on control parameters. The self-adaptive information (which is related entirely to EA, but not to OP under consideration) is appended to the individual's chromosome. While the general work-flow for all EAs remains the same, underlying operators are changed. Here, parent selection operator take a whole population into consideration, the recombination scheme could involve more than two parents to create one child. To construct a child, recombination operator adds alleles from parents in two possible ways: with \textit{uniform} probability for each parent (discrete recombination), or averaging the values of alleles (intermediate recombination). There are two general selection schemes that are used is such algorithms: $(\mu,\lambda)$ which discards all parents and selecting only among offspring highly enriching exploration, and $(\mu+\lambda)$ which includes predecessor Solutions into selection which also known as \textit{elitist selection}~\cite{eiben2015popular}.

\paragraph{Simulated Annealing (SA).} This meta-heuristic is inspired by the annealing technique used in the metallurgy to obtain 'well-ordered' solid state of metal, imposing a minimal internal energy and avoiding semi-stable structures, characterized by local energy minimums. The search process here treated as the metal with a high temperature at the beginning and lowering it to minimum while approaching the end. %SA algorithm handles the optimization objective as annealing threat the material energy. 
SA starts with initial Solution $S$ creation (randomly or using some heuristic) and temperature parameter $T$ initialization. At each iteration, new solution candidate $S^*$ selected within the neighborhood $N(S)$ of current $S$ and the selection criteria evaluated based on $S^*$ quality and temperature parameter $T$. $S^*$ replaces $S$ if (1) optimization objective $f(S^*)$ dominates over $f(S)$ or (2) with a probability that depends on quality loose and current temperature: $p(T, f(S^*), f(S)) = \exp(-\frac{f(S^*) - f(S)}{T})$ for minimization OP and $p(T, f(S^*), f(S)) = \exp(-\frac{f(S) - f(S^*)}{T})$. At each iteration the temperature parameter $T$ is decreased following \textit{Annealing Schedule} also called as \textit{Cooling Rate}: linearly, inverse logarithmic, exponentially~\cite{boussaid2013survey}. The weak side here is that the Annealing Schedule is problem dependent and cannot be determined beforehand, however SA algorithms with parameter control do exist and address this problem by changing the Cooling Rate or temperature parameter $T$ during the search process, refer~\cite{ingber2000adaptive} and~\cite{de2003placement} respectively.

\subsection{Hybrid-Heuristics}
The hybridization of different systems constantly provides a positive effect — you take advantages of one system and merge them with the strong sides from other those getting the best from both of them. The same could be applied for the heuristics. Imagine you have two algorithms biased towards exploration and exploitation respectively. If you use them separately, the expecting results in most cases may be way far from optimal as the outcome of disrupted diversification-intensification balance. But with merging them into say stages of hybrid heuristic, one will obtain both advantages of finding a good quality results and escaping local optima. Most of available hybridization are done exactly with this idea — \textit{staging combination} two heuristics, one exploration and second exploitation suited for getting outperforming hybrid.


\subsubsection{Examples}

The methods to construct hybrid mostly defined by the undertaken heuristics and those, to the best of our knowledge, could not be generalized and classified well, except a \textit{staging} approach, when the output of one algorithm is used as initial state of other, is broadly used. Instead, we will introduce some examples of performed hybridization in order to give you a better understanding of possible hook parts within algorithms and influence of aforementioned balance onto the search process.

\paragraph{Guided Local Search ($GLS$) + Fast Local Search ($FLS$) \cite{tsang1997fast}.}
It is an example of repeatedly applying two heuristics in sequence (staging) and passing the output from one to second one.
The main focus of $GLS$ here is on the Search Space exploration and process guidance using incubated information. In some sort, $GLS$ is closely related to the \textit{Frequency-based memory} used in Tabu Search. In runtime, $GLS$ modifies the cost function of the problem to include penalties and passes this modified cost function to local search procedure. The penalties form memory that describe a local optimum solution and guide the process out of it. A local search procedure then carried out by $FLS$ algorithm. The main feature of $FLS$ is the ability to quickly traverse a neighborhood. It is done by braking it into a number of small sub-neighborhoods, and ignoring those without an improving moves. By performing depth first search over these sub-neighborhoods. At some point of time $FLS$ appears in the local optimum, passes back control to $GLS$ and iteration repeats. 

\paragraph{Direct Global + Local Search \cite{syrjakow1999efficient}.}
As stated in the name this hybridization combines global and local optimization strategies into two-stages: stochastic global pre-optimization and deterministic local fine-optimization. For global optimizations authors apply one of two well-known meta-heuristics — Genetic Algorithm, or Simulated Annealing described earlier in section~\ref{BG: MH Examples} with Meta-heuristics examples. The transition from Global to Local search happens when the predefined conditions are met, for instance when the number of Target System (goal function) evaluations exceeds a boundary or when no distinguishable improvement was done. The Pattern Search~\cite{hooke1961direct} algorithm also known as direct, derivative-free, or black-box search plays role of Local Search heuristic in this combination. Hybrid-heuristic terminates when Pattern Search converges.

\paragraph{Simulated Annealing + Local Search \cite{martin1996combining}.}
After brief explanation of previous two hybrids, an observant reader might make a guess what happens in this particular case, and he will be completely right!
Authors named this method 'Chained Local Optimization', in other words it is yet another representative of staged hybridization. Iteration starts with the current Solution perturbation (authors called this action a 'kick', referring a dramatic change of current position within a Search Space). After this, the Local Search heuristic applies to intensify obtained Solution. When the local optimum reached, the control flow returned to the Simulated Annealing for acceptance criteria evaluation in order to accept or reject a new Solution, what concludes an iteration.


\paragraph{$EMILI$~\cite{pagnozzi2019automatic}} 
Easily Modifiable Iterated Local search Implementation ($EMILI$) is a framework-like system for automatic generation of new (hybrid) stochastic Local Search algorithms. $EMILI$ is a solver for Permutation Flow-Shop Problems (PFSP), also known as Flow Shop Scheduling problems which define a search of an optimal sequence of steps for product creation within a workshop.
Here authors have implemented algorithmic- and problem-specific building blocks, defined grammar-based rules for those building blocks composition and use an automatic algorithm configuration tool $IRACE$~\cite{lopez2016irace} to find a high performing algorithm configurations for problem solving. The work-flow of $EMILI$ could be described in three steps: (1) adaptation of rules to specific representations type of PFSP problem objectives (either Makespan, Sum completion times, Total tardiness), (2) generate a set of possible hybrid heuristics for each of PFSP type and (3) apply iterated racing algorithm implemented in $IRACE$ to select the best performing hybrid for specific problem type. 

From our perspective, described approach of automatic algorithm generation is very close to construction Hyper-Heuristics strategies with off-line learning described in section~\ref{bg: hh}, however authorized to change the system class (from hybrid- to hyper-heuristic) defined by $EMILI$ authors.


\subsection{No Free Lunch Theorem}
A nature question could arise ``If we have all this fancy and well-performing heuristics, why should we spend effort and develop new algorithms, instead of using existing?'' And the answer to this question is quite simple — the perfect algorithm suited for all OP that will do not exist and can not exist. All algorithms that search for optimal parameters of a Target System perform exactly the same, when the results are averaged over all possible Target Systems. If an algorithm is gaining the performance in one problems class, it loses in another class. This is a consequence of so-called \textbf{No Free Lunch Theorem} (NFLT)~\cite{wolpert1997no}.

In fact, one could not predict, how exactly will behave one or another algorithm with problem in hand. A possible and the most obvious way is to probe the specific approach, and analyze it behavior with respect to another in problem solving process. Here simple heuristics and meta-heuristics are out of competition, since if you solved the Optimization Problem once, you wouldn't optimize a second time.
Here come \textbf{Hyper-Heuristics}. We will proceed with their description and how they deal with the NFLT consequences in following section, to not switch the thesis.


\subsection{Hyper-Heuristics}\label{bg: hh}
Lots of state-of-art heuristics and meta-heuristics are developed in a very domain-dependent way, say they use the domain knowledge too intensively to be broadly reused. It motivated research community to raise the level of generality at which the optimization systems can operate and still provide good quality Solutions for various Optimization Problems. The term \textbf{Hyper-Heuristic} (HH) was defined to describe an approach of using some High-Level-(Meta-)Heuristics (HLH) to choose other Low-Level-(Meta-)Heuristics (LLH) and use it to solve the OP in hand. Indeed, a combination of different low-level heuristics produced better results than if hey were applied separately~\cite{drake2019recent}.
It can be explained by the nature of search process and how it evolves in time. When you apply heuristic, it sooner or later converge to some extreme point, hopefully global optimum, since it is `blind' to those not visited regions in the Search Space. But changing the trajectory of investigation by (1) drastically varying the Neighborhood, (2) changing the strategy of Neighborhood exploration and exploitation could (1) bring you to those previously unreachable zones (2) rapidly. However, it is not possible to predict how one LLH will behave in every stage of the search process in comparison to another, here HLH comes to help. In \cite{moriarty1999evolutionary} authors made infer that Hyper-Heuristics can be viewed as a form of Reinforcement Learning, which is sounds logically.

\begin{figure}
	\centering
	\includesvg{HH}
	\caption[Hyper-Heuristics]{Hyper-Heuristics\protect\footnote{Icons from \href{https://thenounproject.com/}{thenounproject.com}}}
	\label{bg:pic:HH}
\end{figure}

%\footnotetext[1]{Icons from \href{https://thenounproject.com/}{thenounproject.com}}


The new concept which implicitly was used in Meta-Heuristics, but explicitly pointed out in Hyper-Heuristics is the \textbf{Domain Barrier}.
As we told previously, HH do not directly tackle an OP, they use LLH instead. This means, that HH are usually unaware of the domain details such as what are those data types, their relationship, etc. within a domain, but rather encapsulates this information in LLHs and those could be used to broader range of Optimization Problems as it is illustrated on picture~\ref{bg:pic:HH}.


\subsubsection{Classification}
Although, the research in Hyper-Heuristics field actively ongoing, a lot of different instances were already created and some trials to organize approaches were conducted~\cite{ryser2014review,drake2019recent,burke2019classification,kerschke2019automated}.
Researchers in their surveys classify HHs by different characteristics, some of them overlap, but it also happens that intriguing parameters distinguished were not highlighted in other works. 

In this section we present some (but not all) facets of Hyper-Heuristics classification to better justify the goal of this thesis.


We begin with the two broadest classes, which differentiate HH \textit{routine} or also called as \textit{nature of High-Level-Heuristic Search Space}~\cite{burke2013hyper,burke2019classification,drake2019recent}.
The first class is the Hyper-Heuristics to \textbf{select} Low-Level-Heuristic, in other words \textbf{Selection Hyper-Heuristic}. In previous sections we were implicitly referring to this class, while talking about Hyper-Heuristic approaches in general. These algorithms operate in the Search Space defined by simple Low-Level-Heuristics that solve Optimization Problem. The task of HLH is to pick the best suited LLH based on available prior knowledge and apply it to OP underway.
The second class is the Hyper-Heuristics to \textbf{construct} or generate LLH by using the atomic components of other heuristics as Lego bricks and following some predefined receipt. These approaches could lead to creating new and unforeseen heuristics that are expected to reveal good performance~\cite{burke2019classification} while solving the problem in hand.


Next, the distinction in \textit{nature of Low-Level-Heuristics Search Space}, in other words how do the LLH derive Solutions for the OP in hand~\cite{burke2013hyper,burke2019classification,drake2019recent}, either by \textbf{constructing} a Solution each time from scratch, or by \textbf{perturbation} of already existing one.


The other broadly used characteristic is the \textit{use of memory}. From this perspective we distinguish Hyper-Heuristics in which the learning happens on-line, off-line or learning mechanisms are not present at all~\cite{ryser2014review,burke2019classification}.
\begin{itemize}
	\item In \textbf{on-line} case, the HH derives an information, used to select among LLH, while those LLH are solving a problem.

	\item In \textbf{off-line} case, the learning happens before solving an Optimization Problem. Here one should first train an HH using other, but homogeneous to current problems. After this preparation step, the HH could be applied to problem in hand.

	\item There exist also \textbf{mixed} cases, where learning happens both on-line and off-line. Definitely it is a promising research direction, despite high dependency on off-line phase.
	
	\item The last case here is an approach \textbf{without learning} mechanisms involved. Usually, these Hyper-Heuristics perform some sort of Random Search selection of LLH.
\end{itemize}


Yet another faced of Hyper-Heuristics classification is the way of assigning \textit{hyper-parameters} (here we use parameters and hyper-parameter concepts interchangeably) for LLHs, or their components~\cite{drake2019recent}. We analyzed surveys and find out that some researchers do not explicitly differentiate approches with respect to nature of parameter settings~\cite{ryser2014review,burke2013hyper,burke2019classification}, while other do~\cite{drake2019recent}:
\begin{itemize}
	\item In \textbf{static} assignment, the underlying heuristics use provided beforehand (usually default) hyper-parameters and do not change them while solving the problem in hand.

	\item The \textbf{dynamic} case uses some kind of rule for parameters changing, specified in advance.

	\item There exist also an \textbf{adaptive} approach, in which HH assigns the parameters for LLH as the response to the learning process. In some sort, it is similar to the parameter control techniques used in Meta-heuristics.
	
	\item And finally, a \textbf{self-adaptive} approach where underlying LLHs comprise \textit{parameter control} techniques and those search for the best solution for OP and own parameter settings simultaneously.
\end{itemize}


For more detailed analysis, description, other classification facets and respective Hyper-Heuristic examples we encourage reader to look into~\cite{burke2003hyper,ryser2014review,drake2019recent,burke2019classification,kerschke2019automated} researches.

\subsubsection{Examples}\label{bg: hh examples}% should I present it in following sections?
\paragraph{HyFlex~\cite{ochoa2012hyflex}}\textit{Hyper-Heuristics Flexible Framework}. It is a software skeleton, created specifically to encourage researchers creating Hyper-Heuristics. It provides the implementation of components for 6 problem domains (Boolean Satisfiability, Bin Packing, Personnel Scheduling, Permutation Flow Shop, Traveling Salesman and Vehicle Routing problems), evaluation functions and a set of Low-Level-Heuristics. The benchmark sets as well as comparison to other existing HH is included to framework. The intent of $HyFlex$ creators to provide these features was to enable others focus directly on High-Level-Heuristics implementation without need to challenge other minor needs and those bring clear comparison among HLH performance~\cite{ochoa2012hyflex}. From the classification perspective, all derivatives from the $HyFlex$ framework are Selection Hyper-Heuristics, however they utilize different learning approaches and hyper-parameter settings. Algorithms, built on top of $HyFlex$ framework could be found in~\cite{misir2012intelligent,ryser2014review,drake2019recent} or on the CHeSC 2011 challenge website\footnote{\href{http://www.asap.cs.nott.ac.uk/external/chesc2011/}{Cross Domain Heuristic Search Challenge website: asap.cs.nott.ac.uk/external/chesc2011/}}.


Along with $HyFlex$, a number of Hyper-Heuristic frameworks is growing, some of them are under active development while others are abandoned:
\begin{itemize}
	\item $Hyperion$~\cite{swan2011hyperion} is a $TH$ (recursive template and hook) framework aiming to extract information from OP search domain for identification of promising components.
	
	\item $hMod$~\cite{urra2013hMod} framework allows not only to construct algorithm components using predefined abstractions (such as $IterativeHeuristic$). In current development stage, developers of $hMod$ are focusing on creation of mechanisms rather than providing a set pre-built heuristics. 
	
	\item $EvoHyp$~\cite{pillay2017evohyp} focus on hyper-heuristics with evolutionary algorithms used as Low-Level-Heuritics. Here authors enable users of framework to construct both selection and generation HHs for both types construction and perturbation LLHs.
	
\end{itemize} 

\paragraph{HITO~\cite{guizzo2015hyper}}\textit{Hyper-Heuristic for Integration and Test Order Problem}. It is an example of HH for selection of LLH. LLHs in this case are presented as a composition of basic EAs operators — crossover and mutation forming multi objective evolutionary algorithms (MOEA). HH  selects those components from $jMetal$ framework\cite{durillo2011jmetal} using interchangeably Choice Function (in form of weighted linear equation) and Multi Armed Bandit based logic to yet again balance exploitation of good LLHs and exploration of new LLHs.


\paragraph{MCHH~\cite{mcclymont2011markov}}\textit{Markov Chain Hyper-Heuristic} is an on-line selective Hyper-Heuristic for multi-objective continuous problems. It utilizes reinforcement learning techniques and Markov Chain approximations to provide adaptive Heuristic selection method. While solving an OP, $MCHH$ updates prior knowledge about the probability of producing Pareto dominating Solutions by each LLH using Markov Chains those guiding an LLH selection process. Applying on-line reinforcement learning techniques, this HH adapts transition weights in the Markov Chains constructed from all available LLHs those updating prior knowledge for LLH selection.

\paragraph{Auto-Sklearn\cite{kerschke2019automated}} Although, the application of Machine Learning (ML) techniques is not a brand-new idea, there exist numbers of automated machine learning systems. They automatically choose the best suited algorithm, feature preprocessing methods for a new dataset at hand with an objective of algorithm's accuracy maximization. From perspective of Optimization Problem solving, automatic ML processes are quite similar to Hyper-Heuristics. They both operate on Search Space of algorithms which later applied to problem in hand with objective to find the best performing one. In particular, based on $Scikit-learn$ framework~\cite{scikit-learn} $Auto-Sklearn$ system uses number of sklearn classifiers to process a data which in some sort similar to usage of LLHs to process a Search Space. Resulting problem, formally called \textit{Combined Algorithm Selection and Hyper-parameter Optimization}problem (CASH) is then solved by hyper-parameter optimization framework $SMAC$~\cite{hutter2011sequential}. We outline a definition of CASH problem as well as description of $SMAC$ framework in~\ref{bg: parameter tuning} and~\ref{bg: smac} respectively.


\subsection{Conclusion on Heuristic Solvers}
To conclude our review on Heuristic approaches for Optimization Problems solving, we shortly remind you pros and cons of each heuristic level.

On the basis remain Simple Heuristics with all their domain-specific knowledge usage and particular tricks for solving problem in hand. Usually, they are created to tackle a concrete problem in hand applying simple algorithmic approach. The simplicity of application and usually fast runtime is balanced by medium solution quality.

On the next level inhabit Meta-Heuristics. They could be compared with more sophisticated hunters which could not only charge directly, but also take a step back when stuck in a dead end. This additional skill enables them to survive in a new environment (Optimization Problem), however some adaptations should be performed to understand the problem and parameter tuning to perform well.

Among with MHs, Hybrid-Heuristics do exist. It is nothing special here, they just took some survival abilities from several Meta-Heuristics hoping to outperform, however still requiring adaptation. In some cases this hybridization provides it advantage, but as time shows, they did not kick out MHs and reside together with their parents. Those we can conclude that the exposed balance between development effort and providing results quality not always assure users to apply them.

Finally, the chosen ones that lead the others, Hyper-Heuristics are inhabitants of the upper level generality. 
Operating by the other Heuristics, HHs analyze how good former are and definitely make use of this knowledge by solving concrete problem using the best suited Heuristic.
Imposing such great abilities, Hyper-Heuristics are able to tackle not only the concrete optimization problem, but entire class of problems, although requiring more development effort.


\section{Parameter Tuning as a Search Problem}\label{bg: parameter tuning}
Proper assignment of hyper-parameters has great impact on exploration-exploitation balance and those on (meta)~-heuristic performance. 
The goal of section: analysis of existing systems for hyper-parameter optimization (tuning), weaknesses and strength of each of the system

\subsection{Approaches for Parameter Tuning}
\paragraph{Grid Search}
\paragraph{Random Search}
\paragraph{Model Based Search}

\subsection{Systems for Model Based Parameter Tuning}\label{bg: parameter tuning expamples}

\subsubsection{IRACE}
\paragraph{approach} \cite{irace:lopez2016irace}
\paragraph{pros and cons}

\subsubsection{SMAC}\label{bg: smac}
\paragraph{approach description}

\subsubsection{BOHB}
\paragraph{approach description}

\subsubsection{AUTO-SKLEARN}
\paragraph{CASH (Combined Algorithm Selection and Hyperparameter optimization) problem}
\paragraph{pros and cons (on-line or off-line, problems to solve, extensibility)}\cite{autosklearn:feurer2015efficient}

\subsubsection{BRISEv2}
\paragraph{approach description}
\todoy{Other systems?}


\section{Parameter control as an Optimization Problem}\label{bg: parameter control}
\subsection{Parameter Control Definition}
\subsection{Examples and Reported Impact}
impact of parameter control based on other's evaluation


\section{Conclusion}

It could be compared with a warp-engine usage on a spacecraft, which gives the possibility to travel faster than speed of light by orders of magnitude. It is definitely fast enough, however if you consider a space-folding engine for instant traveling and use it to jump onto a huge distance, while warp-engine is 


The meta-heuristic systems designers reported positive impact of parameter control embedding. 
However, as the outcome of the no-free-lunch theorem, those systems can not tolerate broad range of problems, for instance, problem classes.
In other hand, hyper-heuristics are designed with an aim to select the low level heuristics and those propose a possible solution of problem, stated in no-free-lunch theorem, but the lack of parameter control could dramatically decrease the performance of LLH (probably, I need to find a prove of this, or rephrase).

\paragraph{Scope of thesis defined.} In this thesis we try to achieve the best of both worlds applying the best fitting LLH and tuning it's parameters while solving the problem on-line.
