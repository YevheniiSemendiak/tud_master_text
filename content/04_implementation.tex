\chapter{Implementation Details}\label{impl}
In this Chapter we dive into the development description of listed in \cref{Concept description} requirements.
 
The best practice in software engineering relies on an implementation effort minimization with help of already existing and well-tested code reuse. With this idea in mind we select one of reviewed in \cref{bg: parameter tuning} open-source parameter tuning frameworks as the code basis for the desired RL-based hyper-heuristic. We also reuse the low level heuristics (LLH) implementation from other meta-heuristics frameworks. The LLH basis may be used almost out-of-box, but the HLH basis requires changes to utilize the reinforcement learning approaches.

In \cref{impl:hlh code basis section} we analyze the parameter tuning frameworks from a perspective of required adaptation effort to implement listed in \cref{concept:prediction} HLH characteristics. We conclude the analysis selecting the best suited HLH code basis in \cref{impl:hlh code basis conclusion}. Afterwards, we split the HLH adaptation process on two similar to presented during the concept description logical parts: in \cref{impl: search space} we discuss the search space development, while \cref{impl: prediction logic} is dedicated to the prediction process. Finally, in \cref{impl: LLH} we perform a code basis selection for LLH, present a set of reused meta-heuristics, their adaptations and the importing process into our hyper-heuristic.


\section{Hyper-Heuristics Code Base Selection}\label{impl:hlh code basis section}
To begin with the analysis of frameworks, let us firstly outline important characteristics from the implementation perspective.

The first two crucial criteria are \emph{variability} and \emph{extensibility} of framework. Since we are planning to use a possibly (but not obligatory) different models for the LLH selection and parameters control, the code basis should be variable in terms of models usage for each prediction level (see \cref{concept:pict:Level-wise prediction process}). The desired HH and specifically HLH should be easily extensible in terms of not only the surrogate models, but also other features such as termination criteria, information filtering, data preprocessing and so forth.

The next criteria is the support for \emph{on-line optimization}. It is a slightly complex system characteristic, which we are willing to distinguish. As it turns out, many parameter tuning systems require full evaluation of target system, other expose early termination mechanisms, but all of them are forcing TS to start solving of the problem at hand each time from scratch. In case of our hyper-heuristic, we treat the LLH configuration evaluation as a trial to improve the problem solution results. It implies an important LLH ability to tackle the (OP) using reinforcement learning approaches (\cref{concept:parameter control}).

The final characteristic is the \emph{conditional parameters} support. This complex feature influence on not only the search space representation mechanisms, but also the prediction process. Therefore, we pay a close attention to both of them from the conditional parameters support perspective.

\subsection{Parameter Tuning Frameworks Analysis}\label{impl: Parameter Tuning Frameworks Analysis}
\paragraph{SMACv3}
We begin our review with the implementation of Sequential Model-based Algorithm Configuration framework, distributed under the BSD-3 license. The idea of SMACv3 lays in an enhancement of the ROAR mechanism with a model-based sampling algorithm. ROAR is a derivative from the FocusedILS algorithm (solver in the parameter tuning framework ParamILS~\cite{hutter2009paramils}), where each evaluation of a new solution candidate on a problem instance was performed sequentially and in isolation. Therefore, since the ROAR evaluation strategy is also used in SMACv3, we found it to require a considerable effort for synchronization the progress between different runs, which enables the on-line problem solving.

As we mention in \cref{bg: smac}, the underlying surrogate model in SMACv3 is selected statically among random forest or Gaussian process kernel density estimator. Both models could fit to complex dependencies among parameters. In the next configuration sampling process the \emph{one-exchange} neighborhood of the best found so far configuration is traversed using the created surrogate model and the expected improvement estimations. An ability of both surrogates to fit a sparse search space is promising, and the usage of expected improvement guarantees to converge the search process to the global optimum given enough time. However, the major drawback in this system is a lack of abilities to include the conditional dependencies between parameters into the sampling process. Since, to the best of our knowledge, the one-exchange neighborhood is unaware of the dependencies, it violates them while sampling and results in illegal parameter values combinations. Those cases are naturally controlled and rejected by the search space representation framework ConfigSpace~\cite{configspace}, but we believe in case of sparse search spaces it could lead to ineffective sampling and system predictive abilities struggling. Unfortunately, we did not find any officially published empirical studies of such cases and could only make guesses based on own intuition, but SMACv3 developers advises for such use-cases\footnote{Visit SMACv3 repository~\url{https://github.com/automl/SMAC3/issues/403}} may serve as an evidence to our assumptions correctness. One of the possible solutions here can be the implementation from scratch of a conditional-aware one-exchange neighborhood definition and for sampling process, which requires much implementation effort.

\paragraph{IRACE} This framework implements the iterated racing algorithm to evaluate a set of configurations during the parameter tuning session (\cref{bg: irace}). The software is distributed under the GNU General Public License with an opened source code.

The framework uses a \emph{Friedman test}~\cite{conover1980practical}, or as an alternative \emph{paired t-test} for statistical analysis of racing in parallel configurations. As the surrogate models, IRACE uses the probability distributions of those parameter values, which are proved to be good during the racing step. The configuration prediction process is defined as the step-wise sampling on previously constructed distributions. It elegantly handles the conditions among parameters and illuminates a possibility of invalid configuration appearance. Unfortunately this solution is static in terms of variability and extensibility on the learning mechanisms.

From the perspective of parallel evaluations, the framework utilizes all available resources at the beginning of each racing step, but as the process continues, fewer evaluations are executed simultaneously, therefore, part of available resources is idling and not utilized completely at all stages of IRACE execution.

For the on-line problem solving support, let us discuss the racing algorithm. As mentioned in \cref{bg: irace}, this step is executed on (1) a set of TS configurations sampled for evaluation and (2) a benchmark set of optimization problems. Multiple instances of TS are initializing with the provided configurations and starting to solve the problem set, while the racing algorithm terminates the worst-performing settings. In case of hyper-heuristic, it is possible to define the benchmark set as a single problem instance divided into parts of TS running time. At each pause we may perform the synchronization of current solutions to proceed with the best found results. Doing so, we adapt the system to on-line problem solving cases, however, the granularity of parameter control will be reduced. The reason for such reduction is the amount of information obtained after each race: only the best configurations are reported leaving the performance evidences of others behind, but we believe this information may be used to create a more precise surrogate models.

\paragraph{HpBandSter} As we discussed in \cref{bg: bohb}, HpBandSter is an implementation of BOHB algorithm, which turns to be a hybridization of Hyperband and Bayesian optimization approaches.

A role of Hyperband in this duet is the configuration evaluation and comparison, while the Bayesian Tree Parzen Estimator (TPE) suggests which configuration to evaluate next. The idea behind this combination lays in elimination of each algorithm weak sides with strengths of the other. For instance, in original Hyperband the configuration sampling is made uniformly at random, which results in a slow converge of an optimization process. On the contrary, a drawback of BO TPE lays in a configuration evaluation process. Naive Bayesian optimization approaches do not take into account the TS performance early evidences. Thus, even when the proposed configuration results in a poor TS initial and intermediate performance, which may be an evidence of a weak final performance, BO still continues the TS execution. These facts motivated authors to merge those two algorithms and create one for parameter tuning with strong anytime (HB) and final (BO) performance. The resulting hybrid effectively uses available computational resources in parallel (HB) in combination with robust learning mechanisms (BO).

Let us discuss the process of handling the conditions between parameters. HpBandSter as well uses ConfigSpace framework for the search space representation. As we discussed during the SMACv3 review, ConfigSpace naturally allows to encode the dependencies and conditions among parameters. TPE learning models are also able to fit these dependencies by means of implemented \emph{impuration} mechanism~\cite{levesque2017bayesian}. Shortly saying, to fill `sparse' configurations with data, the disabled parameters are replaced with their default values. Later, while building the surrogate models those default values are ignored, therefore, the probability density estimations still represent a proper parameter values distributions. However, consider a case of two configurations families appearance: $C_1$ and $C_2$, such that some parameter $P_i$ is forbidden in $C_1$ but required in $C_2$. On the contrary, another parameter $P_j$ is required in $C_1$ but forbidden in $C_2$. If these configuration families are turn to be superior, the resulting probability densities will be biased towards $P_i$ and $P_j$ values. As a consequence, the utilized in HpBandSter prediction mechanism will sample non-default parameter values for both $P_i$ and $P_j$, which results in the configurations with violated parameter dependencies. The sparser the search space, the more harming an effect will be in a prediction performance. The possible treatment here is to change the sampling process by an intermediate layer addition, which will perform the parameter prediction in level-wise approach suggested in \cref{concept:prediction}.

\paragraph{BRISEv2}
BRISEv2 is a software product line (SPL), created with an aim at solving the expensive optimization problems in general and for the parameter tuning in particular (\cref{bg: brise}).

The advantage of BRISEv2 over other systems comes from its \emph{main-node} modular design. It is a set of cooperating core entities (Experiment, Search Space and Configuration) with other non-core entities, exposed to user for variability. The prediction models, termination criteria, outliers detectors, repetition strategies, etc. are representatives of these non-core and variable components. A number of implementations are provided out-of-the-box for all variable entities, but we focus our attention only to the implemented sampling process. The reason of such a greedy review is that the underlying search space representation is carried out by the same ConfigSpace. The provided surrogate models here are ridge regression model with polynomial features and Bayesian Tree Parzen Estimator (TPE). We are not going to repeat ourselves reviewing the ConfigSpace + TPE combination, but we have to put a few words about the ridge regression.

Ridge is the linear regression model with regularization~\cite{hoerl1970ridge}, often used in machine learning field. Being a linear model, its abilities to fit sparse search spaces is poor and, therefore, a machine learning community suggested treating such cases with \emph{conditional linear regression models}~\cite{DBLP:journals/corr/abs-1806-02326}. The underlying idea is to split the search space into sub-spaces and to build separate regression models in each of them. Unfortunately, this approach was not built-in into the ridge regression model used in BRISEv2.

As for the on-line problem solving support, the routine of an optimization process implemented in BRISEv2 is very similar to reinforcement learning. After each new obtained evidence (configuration), a new surrogate model is built to react on the learning process by predicting the next configuration. This facilitates the implementation of problem solving with runtime system adaptations, presented in \cref{concept:parameter control}.

\subsection{Conclusion on Code Base}\label{impl:hlh code basis conclusion}
Most among the reviewed parameter tuning systems share the same SMBO approach for problem solving. They utilize a rather similar techniques for the surrogate models creation and predictions making, however, the different system architectures are implemented. To sum um our review, we utilize the term \emph{quality} to aggregate both (1) provided out-of-the-box the desired characteristic support and (2) the required effort to adapt it, if necessary. For the visual representation, we collect the reviewed characteristic qualities of each software framework into \cref{iml: table code basis selection} and quantize them into three ordinal values:
\begin{enumerate}
	\item \textbf{Poor} quality denotes a weak characteristic support and much effort required to improve it.
	\item \textbf{Average} quality indicates a weak characteristic support, which requires less amount of effort to provide it.
	\item \textbf{Good} quality means a good characteristic support out-of-the-box and requires minor or no changes at all.
\end{enumerate}

\begin{table}[h!]
	\centering
	\begin{tabular}{l||cccc}
		\textbf{Characteristic} & \textbf{SMACv3}& \textbf{IRACE} & \textbf{HpBandSter} & \textbf{BRISEv2} \\
		\hline
		\hline
		Variability \& extensibility & \cellcolor{yellow!25}Average & \cellcolor{red!25}Poor & \cellcolor{yellow!25}Average & \cellcolor{green!25}Good \\
	
		On-line optimization & \cellcolor{yellow!25}Average & \cellcolor{yellow!25}Average & \cellcolor{yellow!25}Average & \cellcolor{green!25}Good \\
	
		Conditional parameters & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{red!25}Poor & \cellcolor{red!25}Poor \\
	\end{tabular}
	\caption{Code basis candidate systems analysis.}
	\label{iml: table code basis selection}
\end{table}

Most of the reviewed software systems were created as an implementation of some concrete algorithm (or combination of algorithms), which results in a system flexibility reduction. Every reviewed framework requires much adaptation effort and the preparation steps should be performed in different parts of a system. Between such features as a proper support of conditional parameters and variability-extensibility, the former plays a settle role in our case. Therefore, we conclude the BRISEv2 framework is the most promising candidate for the hyper-heuristic with parameter control creation.

\section{Search Space}\label{impl: search space}
Previously, in \cref{concept:search space} we presented a set of structural requirements for the search space representation: parent-child relationships should be presented explicitly to allow combinations of different parameter types. For the prediction process support, in \cref{concept:prediction} we listed the functional requirements in a form of mechanisms: data filtering, sampling propagation, parameter description and configuration verification. In this section we analyze the available ConfigSpace framework, how it fits to our requirements and decide whether to use it or to set it aside to perform our own search space representation implementation.

\subsection{Base Version Description}
From the structural point of view, in ConfigSpace\footnote{ConfigSpace GitHub repository: \url{https://github.com/automl/ConfigSpace}} the parameter coupling is made implying parent-child relationship, which fit into our requirements. The set of parameter types suite the most of use-cases and the value-specific dependencies are supported as well. Thus, the structural requirements S.R.1, S.R.2 and S.R.3 are perfectly met.

When it comes to the functional requirements, ConfigSpace samples random configurations in a completion manner. In other words, there is no step-wise process of configuration construction, but only the final and valid results are produced. To the best of our knowledge, there is no straightforward way to expose the underlying parent-child dependencies among parameters and investigate a tiered search space structure, which is required for the prediction models. As a consequence, the data filtering mechanism should be implemented on a side and the sampling propagation as well. The framework exposes an ability to validate a fully created configuration but not a partial one (flat validation). It is also worth to mention that the used in ConfigSpace configuration is a proprietary class. As for the parameter description, the amount of exposed knowledge is satisfying. Here we conclude that the functional requirements, except S.F.R.3, are not met.

As the conclusion, we decided to set aside the $3^{rd}$ party ConfigSpace framework. The reason for dong so is mostly motivated by the amount of required adaptation effort and partially by an involvement of obligatory external dependencies.


\subsection{Search Space Implementation}\label{impl: search space impl}
From the structural requirements we know that the parameters in search space should be treated uniformly. The desired feature tree structure is handled by the \emph{composite} design pattern. With this idea in mind, we construct the search space as a composite \emph{Hyperparameter} object with four possible hyper-parameter types: integer and float as a numerical parameter family, nominal and ordinal as a categorical family. This fulfills specified in \cref{concept:search space} S.R.2.

With the code snippets provided through the explanation we highlight the signatures of implemented methods, which fulfill specified in \cref{Concept description} requirements.

\paragraph{Search space construction.} The S.R.3 (parent-child relationship) implementation is performed by adding a construction method \emph{add\_child\_hyperparameter} in the Hyperparameter class (\cref{impl: S.R.1 listing}). It should be called on a parent object, specifying the activation value(s) (\emph{activation\_categories} argument) of parent hyper-parameter which should expose the child. 

\begin{lstlisting}[language=Python, caption=S.R.1 implementation., label=impl: S.R.1 listing]
class Hyperparameter:
	...
	def add_child_hyperparameter(self, other: Hyperparameter, activation_categories: Iterable[CATEGORY]) -> Hyperparameter
	...
\end{lstlisting}

\textbf{Please note}, currently we require the support of composite construction only by means of categorical parameters, therefore, \emph{add\_child\_hyperparameter} requires a list of activation categories. We postpone an enhancement of composition on numerical ranges for the future work.

\paragraph{Search space role in prediction.}
Imagine several configurations were evaluated and their relative improvement is already estimated. For making the prediction in a tiered approach, the parameter values on a current level should be selected before moving to the next one. For it, we firstly filter data, which fits to this level by means of S.F.R.1. It is implemented in form of recursive hyper-parameter method \emph{are\_siblings}, presented in \cref{impl: S.F.R.1 listing}. The filter accepts already selected parameter values and iterates over the available configurations. At each iteration it finds out, whether the already chosen parameter values (\emph{base\_values}) form a sub-feature-tree of the configuration's under comparison parameter values (\emph{target\_values}). For instance, if the selected LLH type in \emph{base\_values} is not the same as one in \emph{target\_values}, the result will be negative.

\begin{lstlisting}[language=Python, caption=S.F.R.1 implementation., label=impl: S.F.R.1 listing]
class Hyperparameter:
	...
    def are_siblings(self, base_values: MutableMapping, target_values: MutableMapping) -> bool
	...
\end{lstlisting}

After data filtering the time comes to find out, the values of which parameters we must predict. For doing so, the search space, must expose those parameters by means of S.F.R.2 implemented in \emph{generate} method with signature presented in \cref{impl: S.F.R.2 listing}. Since we always interact with a search space root object, the call to \emph{generate} is executed recursively. If a callee finds itself in \emph{values} argument (which depicts the current $parameter\ name \rightarrow parameter\ value$ mapping), it redirects a call to all \textit{activated} children. If it does not, it adds itself a to the \emph{values} and terminates the recursion.

\begin{lstlisting}[language=Python, caption=S.F.R.2 implementation., label=impl: S.F.R.2 listing]
class Hyperparameter:
	...
    def generate(self, values: MutableMapping) -> None
	...
\end{lstlisting}

A randomly sampled for the current level values are then used to obtain the level description. It is then used to (1) cut-off the data from levels above and below (simply selecting the required key-value pairs from the parameter mapping), to (2) build the surrogate models and to (3) make the prediction of parameter values on current level.

The surrogate models creation requires an available data (parameters) description. Thus, the S.F.R.3 implementation is performed in method \emph{describe} with signature presented in \cref{impl: S.F.R.3 listing}. This is once again a recursive call, which terminates, when the parameter object can not find the activated children or himself in the provided \emph{values}. The resulting description is a mapping from the parameter name to its type and range of possible values: either a set of categories for categorical, or lower and upper boundaries for numerical types.

\begin{lstlisting}[language=Python, caption=S.F.R.3 implementation., label=impl: S.F.R.3 listing]
class Hyperparameter:
	...
    def describe(self, values: MutableMapping) -> MutableMapping[Name: [Type, Values]]
	...
\end{lstlisting}

This description is then used by the prediction models for building surrogates and making the parameter values predictions, which replace obtained after \emph{generate} method call randomly sampled values.

The described above process is controlled by means of S.F.R.4, implemented as method \emph{validate} (signature in \cref{impl: S.F.R.4 listing}). The control occurs in two places. Firstly, before starting a new loop of $filter \rightarrow propagate \rightarrow describe \rightarrow predict$ we check whether the construction process is not finished (deep validation), meaning all parameter values were chosen, and we have a valid configuration. Secondly, after making the prediction by models (flat validation), it verifies if the parameter boundaries are not violated. In case of violation, the prediction is discarded and the sampled randomly values are used instead. Since the implemented in search space sampling process (\emph{generate} method) guarantees to provide valid parameter values, after maximally $N$ mentioned above loops, we derive a new and valid configuration, where $N$ is a maximal depth in the defined search space.

\begin{lstlisting}[language=Python, caption=S.F.R.4 implementation., label=impl: S.F.R.4 listing]
class Hyperparameter:
	...
	def validate(self, values: MutableMapping, recursive: bool) -> bool
	...
\end{lstlisting}


\section{Prediction Process}\label{impl: prediction logic}
The next step is an investigation and planning of the prediction logic adaptation.
In \cref{impl: Parameter Tuning Frameworks Analysis} we learned that BRISEv2 provides two learning models: Bayesian TPE and ridge linear regression. Both of them could be used as surrogates within a tiered sampling however, this process should be generalized.

P.F.R.1 implies the addition of entity, which encapsulates the prediction process, described in \cref{impl: search space impl}. We also make this entity responsible for the forgetting strategy, therefore, reaching P.F.R.3. Both requirements are not fulfilled in BRISEv2 yet, hence, we must implement them from scratch.

As for P.F.R.2, the current implementation of BRISEv2 already provides some level of model unification with a required interface. However, during the implementation we found that it implies three logical steps binding: data preprocessing, surrogate models creation and surrogates optimization to predict a next configuration.

The following parts of this Section is dedicated to (1) P.F.R.1 and P.F.R.3 implementation in form of \emph{Predictor} entity, P.F.R.2 fulfillment in form of the data preprocessing mechanisms decoupling from the prediction models. Please note, we postpone the implementation of an elegant surrogate optimization mechanism for future work. Instead, we utilize a simple random search over the surrogate models, since as mentioned in \cref{bg: parameter tuning}, given enough evaluations the random search results becomes comparable to model-based algorithms. Due to a cheap cost of configuration evaluation on surrogate models, we are allowed to do so.

\subsection{Predictor Entity}
In addition to presented logic during the search space description, a role of predictor also lays in decoupling of the learning models from: (1) feature-tree search space shape, (2) other core entities such as Configuration. Besides the static search space, the input for predictor is an available at the moment data (evaluated configurations), while the desired output is a configuration. \cref{impl: P.F.R.1 + P.F.R.3 implementation pseudocode} provides a pseudo-code of the predictor implementation.

To implement the information forgetting mechanism, we utilize the similar idea of \emph{sliding window}, used in hyper-heuristics~\cite{ferreira2017multi}. According to it, the predictor should use a specific number of the latest configurations as information for surrogate models creation. We modify this logic, allowing user to specify not only a static number, but also a percentage of the latest configurations (line 4). It fulfills the P.F.R.3. Naturally, more exotic approaches may arise such as a statistical analysis of diversification or the other types of meta-learning, but we leave it for the future work.

The next step is a prediction models decoupling from the search space structure by means off fulfilling P.F.R.1. As discussed in \cref{impl: search space impl}, to predict parameter values on each level, the models should be built on only related to this level information. For this, after filtering the data (\cref{impl: P.F.R.1 + P.F.R.3 implementation pseudocode}, line 11), predictor propagates the sampling from a previous level to current (line 14) and derives a description for the obtained parameters on current level (line 17-18). Independently, it instantiates a specified in settings surrogate model for this level and fit it with the obtained information (lines 21-23). Afterwards, it requests a prediction from model (will be discussed later) and forwards the prediction for validation by the search space entity (lines 27-28). If either the model cannot properly fit the data, or the prediction is invalid, we keep the sampled randomly parameter values (lines 29-31).

\begin{code}[language=Python, caption=P.F.R.1 + P.F.R.3 implementation pseudo-code., label=impl: P.F.R.1 + P.F.R.3 implementation pseudocode]
class Predictor:
	def predict(measured_configurations):
		# Filter data according to sliding learning window
		level_configurations = trim_in_window(measured_configurations)
		prediction = Mapping()
		
		# Continue prediction until get a valid configuration (Deep validation)
		while not search_space.validate(prediction, recursive=True):
		
			# Filtering the data for current level
			level_configurations = filter(search_space.are_siblings(prediction, x), level_configurations)
			
			# Propagate the prediction
			randomly_generated = search_space.generate(prediction)
			
			# Derive the level description
			full_description = search_space.describe(randomly_generated)
			level_description = trim_previous_levels(description, prediction)
			
			# Cut-off data and build model
			data = trim_accodring_to_description(level_configurations, level_description)
			model = get_current_level_model()
			model.build(data, level_description)
			
			# Predict current level and validate prediction (flat validation)
			if model.is_built():
				level_prediction = model.predict()
				if not search_space.validate(level_prediction, recursive=False):
					level_prediction = randomly_generated
			else:
				level_prediction = randomly_generated
		
		return Configuration(prediction)
\end{code}

For the sake of simplicity we omit some minor implementation details and provide the description of the data preprocessing and available surrogate models below.

\subsection{Data Preprocessing}\label{impl: preprocessing}
The data preprocessing concepts may be split into two complementary parts: an obligatory data encoding and optional data transformation. The first is required to make the underlying model compatible with the provided data. Imagine the parameters values to be a simple strings. Having a surrogate model, which is constructed as the parameter values probability densities (TPE), one should derive a numerical data by encoding those string values into numbers. The second concept is applied on a data, which is already suitable. This is usually done to improve an available surrogate model accuracy by reducing the bias (learning complex dependencies in data), variance (generalization to the unforeseen data) or both. An encoding example could be a simple indexing of all possible string values. It is performed as a replacement of strings by their indexes during the data preprocessing. On a contrary, for the transformation one may try to add the polynomial degrees of available features with an aim to disclose more complex dependencies. The decision on encoding type is often defined by the learning model. On contrary, the decision on data transformation is carried out by the user and depends on the concrete use-case and experience.

All reviewed in \cref{bg: parameter tuning expamples} parameter tuning systems implement the data preprocessing only by means of an obligatory encoding and omitting the possible data transformation. In most of the cases it is implemented as a simple label enumeration and is not encapsulated at all (as an example, check ConfigSpace's Configuration method \emph{get\_array}\footnote{ConfigSpace documentation~\url{https://automl.github.io/ConfigSpace/master/API-Doc.html}}). Being the most straightforward approach, this encoding may introduce a non-existing patterns in categorical data. For instance, having 3 possible LLH types: genetic algorithm, simulated annealing and evolution strategy, it will encode such parameter values to numbers 0, 1 and 2 respectively. When such encoded data is passed to the surrogates for learning, some models may interpret it as follows: GA is closer to SA than to ES, the distances from SA to two others algorithms are equal within a search space. To prevent this, the other type of preprocessing should be used, for instance, binary encoding.

In any case, the intent of this discussion is to provide an insight of data preprocessing importance for the reader, but the discussion of possible cases and their influence are out of this thesis scope. Here we decided to gain a certain level of flexibility by providing a uniformed wrapper for the preprocessing routines implemented in Scikit-learn machine learning framework~\cite{scikit-learn}. We omit the details of wrapper implementation since it is a single object decorator, instantiated with the provided preprocessing unit. The wrapper is executed each time before the actual surrogate performs learning and after making the prediction to inverse the transformation.

To make the models and data preprocessing units interfaces compatible, we store the data in form of DataFrames --- tabular data representation carried by Pandas framework~\footnote{Pandas Github repository~\url{https://github.com/pandas-dev/pandas}}. In \cref{impl: P.F.R.1 + P.F.R.3 implementation pseudocode} line 21 denotes a step of configuration objects transformation to DataFrame, keeping only the current level features.


\subsection{Prediction Models}\label{impl: prediction models}
As a derivative from predictor implementation, the underlying prediction models should expose a unified interface and behavior. Due to tiered prediction process, the surrogate models are acting on a search space levels without forbidding dependencies. This enables us to use in addition to previously discussed surrogates a vast range of other learning algorithms, for instance, linear regression models. In fact, a previously used in BRISEv2 ridge regression with polynomial features is nothing else, but a combination of data preprocessing step with the ridge regression model from Scikit-learn framework. Later in this Section we discuss an implementation of a unified wrapper for Scikit-learn linear models.

As a step further, we also add the implementation of multi-armed bandit (MAB): a selection strategy proposed in~\cite{auer2002finite}. It is motivated by a promising performance of the reviewed in~\cite{auer2002finite} selection hyper-heuristics built on MAB. Please note, MAB is applicable only to categorical parameters types.

We also decouple the previously available in BRISEv2 Bayesian TPE from the data preprocessing logic, however, no other major changes except refactoring are required. Thus, there is no reason for the detained TPE implementation discussion here.

\subsubsection{Scikit-learn Linear Model Wrapper}\label{impl: sklearn wrapper}
Scikit-learn is one among the most popular open-source machine learning frameworks. As a consequence of flexible architecture, Scikit-learn often plays a central role in other products providing implementations of numerous building blocks for machine learning pipelines. This advantage in combination with a comprehensive documentation resulted into a large and active framework community\footnote{Scikit-learn GitHub repository~\url{https://github.com/scikit-learn/scikit-learn}}.

All available in Scikit-learn linear regressors implement the same interface and usage routines. For instance, before making a prediction, the regression model should be trained on a preprocessed data, providing \emph{features} and \emph{labels}. Afterwards, one may use model to make a prediction for unforeseen features and the surrogate will produce a corresponding label according to the learned dependencies. This implies that for finding the best parameter combination, one should still solve the original optimization problem but with the reduced evaluation cost.

To reuse the available in framework surrogate models, we create the wrapper as an object decorator, implementing the required in \emph{Predictor} \emph{Model} interface. The pseudo-code of this wrapper is presented in \cref{impl: sklearn model wrapper pseudo-code}.

During the model creation, we firstly instantiate features and labels preprocessors, and transform the input data (lines 4-6). The creation process includes also a model accuracy verification step, which is performed by means of cross-validation: splitting the set of data into \textit{k} disjoint folds, training \textit{k} model each time excluding one fold for accuracy verification (line 9). If the potential model average accuracy is less the predefined threshold, the model is considered to be not precise enough and, therefore, rejected (line 15), forcing the predictor to use random parameter values. However, if the model is able to perform well, we train it on an entire dataset and store for further usage (lines 12-13).

Later, for making the prediction by means of random search (if the model was built successfully), we firstly sample parameter values of this level uniformly at random (line 20). Afterwards, we transform them using the same preprocessors, applied during the model construction (line 21). Then, we make a prediction for randomly sampled features using the surrogate model and transform those predictions back into original labels (lines 23-24). Finally, we select the best features (encoded parameter values) by means of the predicted labels, reverse it transformation and return to \emph{Predictor} (lines 27-28).

\begin{code}[language=Python, caption=Scikit-learn linear model wrapper pseudo-code., label=impl: sklearn model wrapper pseudo-code]
class SklearnModelWrapper(Model):
	def build_model(features, labels, features_description):
		# Execute data preprocessing
		features_preprocessors, labels_preprocessors = build_preprocessors()
		transformed_features = features_preprocessors.transform(features)
	 	transformed_labels = labels_preprocessors.transform(labels)
	 	
	 	# Build model and check its accuracy
	 	accuracy = cross_validation(model, transformed_features, transformed_labels)
	 	if accuracy > threshold:
	 		# Training on all available data
	 		model.fit(transformed_features, transformed_labels)
	 		model_is_built = True
	 	else:
	 		model_is_built = False
	 	return model_is_built
	 
	 def predict():
	 	# Solving surrogates optimization problem by means of random search
	 	features = random_sample(features_description)
	 	features_transformed = features_preprocessors.transform(features)
	 	
	 	labels_predicted_transfored = model.predict(features_transformed)
	 	labels_predicted = labels_preprocessors.inverse_transform(labels_predicted_transfored)
	 	
	 	# Select those parameter values, which maximize RI
	 	prediction_transformed = select_by_labels(features_transformed, labels_predicted)
	 	prediction = features_preprocessors.inverse_transform(features_transformed_chosen)
		return prediction
\end{code}

\subsubsection{Multi-Armed Bandit}\label{impl: FRAMAB}
Originally, the multi-armed bandit (MAB) problem was introduced in~\cite{robbins1952some} and defined as follows: for a given set of choices $c_i$ with unknown stochastic reward values $r_i$, which are distributed normally with variance $v_i$, the goal is to maximize the accumulated reward, sequentially selecting several times among available choices $c_i$. The problem obtained its name as an analogy to one-hand slot machines in casino and naturally denotes the well-known exploration versus exploitation dilemma.

In most of the times, MAB is solved by reinforcement learning (RL) approaches, which analyze the already available evidences before performing each next step. It perfectly fits to our requirements of sequential LLH to tackle the problem at hand, therefore, those choices are nothing else, but LLH types (categories of categorical parameter). In~\cite{auer2002finite} the authors proposed the Upper Confidence Bound algorithm as an intuitive MAB solution: in iteration $k$, among available categories select one with a maximal UCB value. The UCB for each category is calculated according to \cref{impl: ucb formula}, where first component $Q$ is a quality of category under evaluation and represents the exploitation portion of UCB. The second component estimates the exploration portion and evaluates the number of time each category was selected. The multiplier $C$ is a balancing coefficient.

\begin{equation}
UCB = Q + C \cdot \sqrt{\frac{2 \log \sum_{1}^{i} n_k^i}{n_k}}
\label{impl: ucb formula}
\end{equation}

In this work we implement a proposed in~\cite{li2013adaptive} Fitness-Rate-Average-based MAB (FRAMAB) with two reasons: (1) it is an intuitive and robust approach, (2) according to the benchmarks in~\cite{ferreira2017multi} it outperforms other MAB algorithms. In FRAMAB, $n_k^i$ denotes the overall number of categories, while $n_k$ is a number of times the category under evaluation was selected. The quality estimation $Q$ in FRAMAB is the average improvement, obtained by the underlying category.

As for the balancing coefficient $C$, the authors in~\cite{ferreira2017multi} were evaluating a range of values between $10^{-4}...10^{-1}$. The dominance of $C$ values for various problem types were different, therefore we expose it to user for configuration. 

In addition to the statically defined $C$ value, we propose a mechanism for $C$ estimation as a standard deviation in improvement values. The motivation for this is following: if there exists an uncertainty in category domination, the deviation will be high and it should encourage the exploration portion of UCB values. We do not provide a pseudo-code for this model implementation since it straightly repeats the provided above algorithm description.


\section{Low Level Heuristics}\label{impl: LLH}
When our HLH is ready to solve an OP, the time comes to provide the tools for solving. A role of LLH in our hyper-heuristic (HH) may play every algorithm starting from a single heuristic and ending with meta-heuristic (MH) or even other HH. As we discussed in \cref{bg: mh}, nowadays the MH research is referred as the framework growth time. Therefore, we are able not only to reuse a single meta-heuristic but to instantiate a set of underlying heuristics among available in relative frameworks. Thus, in this Section we present a review of several meta-heuristic frameworks with an intent to select the best suited one, implement a facade for framework usage and utilize the available algorithms as LLHs in our hyper-heuristic.

Before diving into description we briefly outline the LLHs characteristics with respect to which we analyze each framework:
\begin{enumerate}
	\item \textbf{Set of meta-heuristics}, which we will be able to use as LLHs in our HH.
	
	\item \textbf{Exposed hyper-parameters}, which are required for LLH tuning. We point it out explicitly, since it happens so that the parameters of an algorithm are exposed not fully.
	
	\item \textbf{Set of supported optimization problems}, which will define the applicability of our HH. The wider this set, the more use-cases developed HH is able to tackle.
	
	\item \textbf{Warm-startup}, which is required to continue the problem solving from a previously reached solution. The underlying LLH should not only report the finally found solution(s) but also to accept them as the starting points.
	
	\item \textbf{Termination criteria}, which is needed to control the intermediate results of optimization process by HH. In our system we use the wall-clock time termination to stop the LLH and report the results.
\end{enumerate}


\subsection{Low Level Heuristics Code Base Selection}\label{implementation:llh code basis selection}
We distinguish the following frameworks as the LLH code basis candidates: Solid\footnote{Solid GitHub repository~\url{https://github.com/100/Solid}}, mlrose\footnote{mlrose GitHub repository~\url{https://github.com/gkhayes/mlrose}}, pyTSP\footnote{pyTSP GitHub repository~\url{https://github.com/afourmy/pyTSP}}, LocalSolver\footnote{LocalSolver website~\url{https://localsolver.com}}, jMetalPy\footnote{jMetalPy GitHub repository~\url{https://github.com/jMetal/jMetalPy}} and jMetal\footnote{jMetal GitHub repository~\url{https://github.com/jMetal/jMetal}}.

\paragraph{Solid.} A framework for gradient-free optimization. It comprises a wide range of MH skeletons with exposed hyper-parameters: genetic algorithm, evolution algorithm, simulated annealing, particle swarm optimization, tabu search, harmony search and stochastic hill climbing. The support of warm-startup is not provided and it requires changes in each algorithm as a consequence of the shared base class absence. As for the termination criteria, algorithms in this framework support the maximal number of TS evaluations-based and desired quality-based but not the time-based termination. Once again, to add new criterion, one should modify the code of all algorithms. The framework does not provide the problem instances, nor domain-dependent parts of algorithms, therefore, to use it one will need to carry out not only a domain-specific adaptation but also a problem description.

\paragraph{mlrose.} A framework with implementation of various well-known stochastic optimization algorithms such as: naive and randomized hill climbing, simulated annealing, genetic and mutual-information-maximizing input clustering (MIMIC) algorithms. Each listed solver is implemented with an exposed set of hyper-parameters. It is possible to control an initial state, which is handy in our case. As for the implemented OPs, the framework comprises a large set of different types: one max, flip-flop, four and six peaks, continuous peaks, knapsack, traveling salesman, n-queens and max-k color optimization problems. The proposed termination criteria are represented only by one criterion controlling the number of TS evaluations. As in the previous framework, here the algorithms are not sharing the same code basis therefore, it may require much effort for their adaptation in general and to introduce a new termination criterion in particular.

\paragraph{pyTSP.} A system, specially designed to tackle the traveling salesman problem. Together with visualization techniques, it also provides a wide bunch of different algorithms. Here they are divided into four groups. First are construction heuristics with nearest neighbor, nearest insertion, farthest insertion and cheapest insertion algorithms. Second is a linear programming algorithm. Third are perturbation heuristics among which pairwise exchange, also known as 2-opt, node insertion and edge insertion. Fourth group formed from meta-heuristics and represented by the genetic algorithm. As one may expect, the only supported problem type here is the TSP, moreover the representation of problem does not follow a broadly used in research community manner. The other drawbacks of this framework is a partial hard-coding of hyper-parameters and an absence of exposed termination criteria. Also, the construction heuristics by their nature do not expose the possibility to feed them with the initial solutions. However, in some other algorithms the functionality to specify the initial solution is provided.

\paragraph{LocalSolver.} A commercial optimization tool with free academic license. It is implemented in C++, and the API is exposed to such programming languages as Python, C++, Java and C\#. The software implements a local search programming paradigm~\cite{benoist2010toward,benoist2011localsolver}, therefore, the algorithm itself and its parameters are not exposed. It is required from the user to provide a solver-specific problem description. Thanks to a detailed documentation, the desired TSP example could be found among numbers of other optimization problems. Two possible termination criteria are exposed: a wall-clock time and a number of solver iterations. Also, the framework supports a possibility to set an initial solution for the solver, therefore, it looks like a good candidate for the LLH. Unfortunately, our trial to use the tool showed up that the provided academic license could not be easily used within BRISEv2 containerized architecture. A possible work-around is to deploy a license server on a host machine and force workers to register themselves, but we found this to be an expensive task requiring much implementation effort.

\paragraph{jMetalPy.} An open-source meta-heuristic framework for multi- and single-objective optimizations. Among the provided single-objective algorithms one will find genetic algorithm, evolution strategy, local search (hill climber) and simulated annealing. Even if the list of proposed heuristics is not the largest in comparison to other reviewed frameworks, every implemented algorithm exposes its hyper-parameters for tuning. We also found the code to be well-structured, therefore, in case of required changes they could be made with less effort. A functionality for heuristic solver warming-up is available out-of-the-box. The various termination criteria are ready as well, among which the wall-clock time-based and the number of TS evaluations-based criteria. The list of supported single-objective optimization problems consists of knapsack, traveling salesman and four other synthetic problems: one max, sphere, Rastrigin and subset sum.

\paragraph{jMetal.} A meta-heuristic framework implemented in Java is an alternative to previously reviewed Python-based jMetalPy. This framework also provides meta-heuristics for multi- and single-objective OP. For SO OP, jMetal developers implemented the following algorithms: naive and covariance matrix adaptation evolution strategies (CMA-ES), genetic, particle swarm (PSO), differential evolution and coral reef optimization algorithms. It is worth to mention that not all solvers are universally applicable to a wide range of OPs. For instance, CMA-ES, PSO and differential evolution can be applied only to OPs with continuous numeric input such as synthetic mathematical problems. In contrast to implemented in Python jMetalPy, jMetal supports only one termination criterion, based on number of TS evaluations, and do not support algorithm warming-up at all.

\paragraph{} To sum up our discussion, we aggregate the described characteristics in \cref{iml: table llh selection}, which is similar to \cref{iml: table code basis selection}, presented during the HLH code basis selection. Once again, the characteristics qualities are scored into three ordinal values: poor, average and good with respect to provided functionality and required effort for adaptation.

\begin{table}[h!]
	\centering
	\begin{tabular}{l||cccccc}
		\textbf{Characteristic} & \textbf{Solid} & \textbf{mlrose} & \textbf{pyTSP} & \textbf{LocalSolver} & \textbf{jMetalPy} & \textbf{jMetal} \\
		\hline
		\hline
		Set of heuristics & \cellcolor{red!25}Poor & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & N/A & \cellcolor{yellow!25}Average & \cellcolor{green!25}Good \\
		
		Exposed hyper-parameters & \cellcolor{green!25}Good & \cellcolor{green!25}Good & \cellcolor{red!25}Poor & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{green!25}Good \\
		
		Provided OPs & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{yellow!25}Average & \cellcolor{yellow!25}Average \\
		
		Warm-startup support & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{green!25}Good & \cellcolor{yellow!25}Average \\
		
		Termination criteria & \cellcolor{yellow!25}Average & \cellcolor{red!25}Poor & \cellcolor{red!25}Poor & \cellcolor{green!25}Good & \cellcolor{green!25}Good & \cellcolor{yellow!25}Average \\
	\end{tabular}
	\caption{Meta-heuristic frameworks characteristics.}
	\label{iml: table llh selection}
\end{table}

Our ultimate goal is not to reach the best performance in provided solution, but to investigate, whether a proposed concept is able to outperform the baseline performance measures. Thus, while selecting LLH, the quality of provided heuristics and their hyper-parameters are playing a crucial role. For our experiments we decided to use three LLHs: two MHs from Python-based jMetalPy (simulated annealing and evolution strategy) and one from Java-based jMetal (evolution strategy).


\subsection{Scope of Low Level Heuristics Adaptation}\label{impl: LLH scope}
The selected frameworks propose many algorithm implementations. Since the same people are developing both jMetal and jMetalPy, the overall architecture of both frameworks is similar. Nevertheless, the proposed features are slightly different. For instance, jMetal does not provide time-based termination, nor warming-up the solver by initial solutions. Therefore, we split the adaptation  of frameworks onto two parts, one is dedicated to jMetalPy and in the other we discuss jMetal.

\paragraph{jMetalPy.} During the analysis above we found that the provided features are greatly fit our requirements. Even if the lists of implemented MHs and supported OPs are not that wide, we could simply reuse the provided out-of-box implementations. For doing so, we implement a framework wrapper (see \cref{impl: jMetalPy framework wrapper pseudo-code}), which creates a desired optimization problem instance, MH solver instantiate with the provided hyper-parameters (line 3). Later, we call this wrapper to start a solver execution and report the results in a framework-independent way (line 5). To prevent an expensive problem instances loading within one optimization session, we cache it in memory (lines 8-9). Also, we cache an expensive I/O introspection calls, which are used to find framework components: algorithms, termination criteria or different algorithm operators such as mutation, selection, crossover, etc. (lines 11-15).

\begin{code}[language=Python, caption=jMetalPy framework wrapper pseudo-code., label=impl: jMetalPy framework wrapper pseudo-code]
class JMetalPyWrapper(ILLHWrapper):

	def construct(hyperparameters: Mapping, scenario: Mapping, warm_startup_info: Mapping) -> None
		# Constructing meta-heuristics initialization arguments, attach initial solutions
	def run_and_report() -> Mapping

	# jMetalPy framework introspection helper methods
	@lru_cache()
	def _get_problem(problem_name, init_params)
	
	@lru_cache()
	def _get_algorithm_class(mh_name)
	
	@lru_cache()
	def _get_class_from_module(name, module)
\end{code}

While experimenting with the framework, we found several implementation flaws in algorithms or their components. The fixes for these bugs were submitted as contributions\footnote{jMetalPy PR 1:~\url{https://github.com/jMetal/jMetalPy/pull/67}}\footnote{jMetalPy PR 2:~\url{https://github.com/jMetal/jMetalPy/pull/80}} to implemented open-source framework.

\paragraph{jMetal.} On the contrary to jMetalPy, this framework is implemented in Java, therefore, we can not perform the software instantiating straightforwardly, since BRISEv2 workers are based on Python. There are several libraries which allow to execute a Java code within Python: JPype\footnote{JPype GitHub repository:~\url{https://github.com/jpype-project/jpype/}}, Py4J\footnote{Py4J GitHub repository:~\url{https://github.com/bartdag/py4j}} or PyJNIus\footnote{PyJNIus GitHub repository:~\url{https://github.com/kivy/pyjnius}}. The usage of one among listed modules enables us to build the same framework wrapper, as we did in previous case. Since currently we are planning to use only one meta-heuristics, the implementation of such wrapper will be unreasonable. Thus, to use a provided in jMetal evolution strategy, we pack it into an executable file with exposed parameters and call it from worker script, providing hyper-parameters settings and warming-up solutions.

\subsection{Low Level Heuristic Runner}
When the MH wrappers are ready, we use them as different execution strategies of low level heuristic with unified \texttt{ILLHWrapper} interface. To operate these wrappers we implement a separate entity: \emph{LLH runner}. It forwards the construction and execution commands to the wrapper, tracks the state, make general information logging and pass the results after execution back to HLH. This enables us to easily scale workers horizontally since they are homogeneous and state-less (not taking into account the caching mechanisms). The resulting process of LLH execution from the worker perspective is represented as a sequence diagram in \cref{impl:pict:llh sequence diagram}. Please note, within an implemented approach the meta-heuristics are reinitialized at each external iteration (between each task execution). Therefore, algorithms as simulated annealing are `restarting' between tasks dropping such internal parameters as temperature (in SA) to it's initial state.

\svgpath{{graphics/Impl/}}
\begin{figure}
	\centering
	\includesvg[width=\textwidth]{LLH}
	\caption{The low-level heuristic execution process.}
	\label{impl:pict:llh sequence diagram}
\end{figure}

\section{Conclusion}
The performed implementation of proposed in \cref{Concept description} concept was done reusing the existing frameworks. The hyper-heuristic is mostly based on the modular BRISEv2 framework for parameter tuning. We utilize BRISEv2 prediction models in form of reinforcement learning as a HLH, while several homogeneous workers are carrying out the optimization process using their LLHs. For the LLHs implementation we reuse the existing meta-heuristic frameworks jMetalPy and jMetal. Despite the selected code basis, the proposed approach could be implemented in most of the parameter tuning systems following SMBO methodology, however, requiring the adaptation according to our review in \cref{impl:hlh code basis section}.

While adapting BRISEv2, we were forced to set aside the previously used search space representation and implement our own to handle the tiered configuration prediction process and the sparseness issue. An intermediate entity \emph{predictor} was added to decouple the search space shape from the learning-prediction process. It allowed us to extend the previously available models with the several others: fitness-rate-average based multi-armed bandits (FRAMAB) for categorical parameter selection and linear regressors from Scikit-learn framework as surrogates models. We also decoupled data preprocessing step reusing the respective tools from Scikit-learn framework.

We believe the proposed implementation will serve well not only as a hyper-heuristic, but also as old good parameter tuning framework.