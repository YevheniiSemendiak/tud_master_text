\chapter{Conclusion}
\todor{answer research questions}
comparison to HITO~\cite{guizzo2015hyper}

%TODO: need to add a review of available techniques for making a predictions within conditional search spaces
% https://arxiv.org/pdf/1909.13404.pdf - omg, 30.09.2019 -_-, smth really similar to proposed here approach..

\paragraph{Hyper-Heuristics with parameter tuning (or better say, control?), Constrainted Parameter Tuning and Architecture search problems all are the same?}
All these problems are seems to talk about the same thing, and trying to solve it in the same ways, while calling it differently. In one hand, it could be the result of relatively young research direction (in all cases). In other hand we could make such an assumption because knowledge lack $\smile$.

Hyper-Heuristics and Automatic Machine Learning are the same.

\paragraph{Other worth-to-try approaches}
Selecting LLH and parameters according to Markov Decision Process: use discretization of parameters and predict reward using MCMC.

% highlight that such MHs as Simulated Annealing are now "restarting". It measn, that is in SA case, the Temperature parameter change drops to initial state. Thus here we obtain Iterative Simulated Annealing