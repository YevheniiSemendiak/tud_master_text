\chapter{Conclusion}\label{conclusion}
Before making a final conclusion, let us briefly remind our objective.
The task of this thesis was defined as follows: using an existing parameter tuning software proposes a concept to (1) perform the parameter control in meta-heuristics on a generic level and (2) make both algorithm selection and parameter control solve the optimization problem at hand. In our research the complex objective was split into several compound tasks, which were formulated in three research questions (\cref{intro: research objective}). Here we provide explicit answers to each of them.

The proposed in this thesis generic parameter control approach relies on two aspects. Firstly, it should be possible to evaluate the performance of the system under control with specified configuration at any time. The ideal option is to limit the system execution with the budget specified beforehand (number of iterations, wall-clock time, etc). Secondly, it should be possible to change the target algorithm configuration and proceed with the execution basing on previously obtained results. We use the reinforcement learning methodologies to traverse the parameter space, evaluating the performance of unforeseen configurations iteratively, while solving the problem at hand. The proposed concept of generic parameter control was examined in \cref{eval:1:PC} with three meta-heuristics: two Python-based algorithms, namely, simulated annealing and evolution strategy and one Java-based evolution strategy. The proposed approach revealed its applicability by reaching, and in some cases even outperforming the results of tuned in offline algorithm parameters. Therefore, we answer the \textbf{RQ1}: it is indeed possible to perform the algorithm configuration at runtime on the generic level. Please note, the use-cases of our concept are defined by the algorithms, in which execution time is much larger than time spent to parameter control routines (see \cref{concept:parameter control}).

\paragraph{RQ2} \emph{Is it possible to simultaneously perform algorithm selection and parameters adaptation while solving an optimization problem?}

Our idea of merging those two problems lays in treating the algorithm type as a regular categorical parameter in the search space. By utilizing the parent-child relationships we define dependent parameters in such search space and perform the selection by means of firstly sampling the independent parameters and hiding the children, and secondly fixing the selected for parents' values and exposing the \emph{activated} children parameters. The proposed stepwise process of configuration construction provides a possibility to utilize a wide range of surrogate models for learning the dependencies among parameter values on each level in isolation. The requirements and use-cases of the proposed approach remain the same as for the generic parameter control technique defined above.


\paragraph{RQ3} \emph{What is the effect of selecting and adapting algorithms while solving an optimization problem?}

The performed in \cref{eval:1:hh-pc} evaluation and analysis of the simultaneous online algorithm selection and parameter control revealed its applicability. More specifically, given the same wall-clock time and environment setup, HH-PC was able to outperform the best underlying tuned meta-heuristics for kroA100 TSP instance. For a slightly larger pr439 example, HH-PC results were comparable with the best tuned in offline meta-heuristic. With problem size growing further, the gap between HH-PC and the best available solver, used in isolation with tuned parameters increases. However, comparing the averaged quality of all available solvers used in isolation with the results of our approach, we observe a strong domination of later. Therefore, our answer to \textbf{RQ3} is the following: HH-PC constantly produces good quality results and should be considered if the meta-heuristics domination and their hyper-parameters are unknown beforehand. However, a considerable amount of solution quality is sacrificed to tackle APSP problem, in comparison to the best underlying algorithm usage with tuned parameters.


\paragraph{}
An explicit list of this thesis contributions is the following:
\begin{enumerate}
	\item The concept of reinforcement learning-based generic parameter control in meta-heuristics was proposed and empirically evaluated.% on three meta-heuristic implementations proved its ability to reach the performance of tuned in offline parameters.
	
	\item The unification of both online algorithm selection and generic parameter control approaches into single APSP is performed. The approach to tackle APSP is proposed by means of reinforcement learning-based online selection hyper-heuristic with parameter control in low-level meta-heuristics.

	\item The usability of an existing parameter tuning SPL BRISEv2 was extended with aforementioned use-cases without losing the flexibility of a wide range of learning models usage. Moreover, the concept of data preprocessing was encapsulated.
\end{enumerate}

We consider the task of this thesis accomplished and the proposed reinforcement learning-based generic parameter control and algorithm selection approaches useful for solving the optimization problems with the help of meta-heuristics.